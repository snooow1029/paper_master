/**
 * Simple GROBID Citation Service for testing
 * Step-by-step testing of GROBID PDF parsing functionality
 */

import axios from 'axios';
import FormData from 'form-data';
import * as cheerio from 'cheerio';
import * as fs from 'fs';
import * as path from 'path';
import { SemanticScholarService } from './SemanticScholarService';
import { Paper } from '../entities/Paper';

interface GrobidTestResults {
  connection: boolean;
  pdfDownload: boolean;
  grobidProcessing: boolean;
  teiParsing: boolean;
  error?: string;
}

interface TeiAnalysisResult {
  hasReferences: boolean;
  referenceCount: number;
  hasCitations: boolean;
  citationCount: number;
  sections: string[];
}

export class AdvancedCitationService {
  private grobidBaseUrl: string;

  constructor(grobidUrl?: string) {
    // ÂÑ™ÂÖà‰ΩøÁî®ÂÇ≥ÂÖ•ÁöÑ URLÔºåÂê¶ÂâáÂæûÁí∞Â¢ÉËÆäÊï∏ËÆÄÂèñ
    const url = grobidUrl || process.env.GROBID_URL;
    
    if (!url) {
      console.error('WARNING: GROBID_URL environment variable is not set.');
      console.error('GROBID features will be disabled. Please set GROBID_URL to enable PDF parsing.');
      // Ë®≠ÁΩÆ‰∏ÄÂÄãÈªòË™çÂÄº‰ª•ÈÅøÂÖçÂ¥©ÊΩ∞Ôºå‰ΩÜÊúÉÂú® testGrobidConnection ‰∏≠ËøîÂõû false
      this.grobidBaseUrl = 'http://localhost:8070';
      return;
    }
    
    this.grobidBaseUrl = url;
    console.log(`Using GROBID connection at: ${this.grobidBaseUrl}`);
  }

  /**
   * Test if GROBID service is available
   */
  async testGrobidConnection(): Promise<boolean> {
    // Â¶ÇÊûú GROBID_URL Êú™Ë®≠ÁΩÆÔºåÁõ¥Êé•ËøîÂõû false
    if (!process.env.GROBID_URL && this.grobidBaseUrl === 'http://localhost:8070') {
      console.log('GROBID_URL not configured, skipping GROBID connection test');
      return false;
    }
    try {
      console.log(`Testing GROBID connection at: ${this.grobidBaseUrl}`);
      
      const response = await axios.get(`${this.grobidBaseUrl}/api/isalive`, {
        timeout: 5000
      });
      
      console.log(`GROBID connection test: ${response.status === 200 ? 'SUCCESS' : 'FAILED'}`);
      return response.status === 200;
      
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      console.error('GROBID service not available:', errorMessage);
      return false;
    }
  }

  /**
   * Normalize arXiv URL to PDF URL format
   * Supports: /abs/, /pdf/, /html/ formats
   */
  private normalizeArxivUrlToPdf(url: string): string {
    // Extract arXiv ID from various formats
    let arxivId: string | null = null;
    
    // Format 1: https://arxiv.org/abs/2411.00154v1
    const absMatch = url.match(/arxiv\.org\/abs\/([^?\/\s]+)/i);
    if (absMatch) {
      arxivId = absMatch[1];
    }
    
    // Format 2: https://arxiv.org/pdf/2411.00154v1.pdf
    if (!arxivId) {
      const pdfMatch = url.match(/arxiv\.org\/pdf\/([^?\/\s]+)(?:\.pdf)?/i);
      if (pdfMatch) {
        arxivId = pdfMatch[1];
      }
    }
    
    // Format 3: https://arxiv.org/html/2411.00154v1
    if (!arxivId) {
      const htmlMatch = url.match(/arxiv\.org\/html\/([^?\/\s]+)/i);
      if (htmlMatch) {
        arxivId = htmlMatch[1];
      }
    }
    
    // Format 4: Direct arXiv ID (e.g., 2411.00154v1)
    if (!arxivId) {
      const idMatch = url.match(/^([0-9]{4}\.[0-9]{4,5}(?:v[0-9]+)?)/);
      if (idMatch) {
        arxivId = idMatch[1];
      }
    }
    
    if (!arxivId) {
      throw new Error(`Unable to extract arXiv ID from URL: ${url}`);
    }
    
    // Return normalized PDF URL
    return `https://arxiv.org/pdf/${arxivId}.pdf`;
  }

  /**
   * Test downloading PDF from arXiv URL
   * Now supports: /abs/, /pdf/, /html/ formats
   */
  async testPdfDownload(arxivUrl: string): Promise<Buffer | null> {
    try {
      console.log(`Testing PDF download from: ${arxivUrl}`);
      
      // Normalize URL to PDF format (supports abs, pdf, html)
      const pdfUrl = this.normalizeArxivUrlToPdf(arxivUrl);
      
      console.log(`Normalized PDF URL: ${pdfUrl}`);
      
      const response = await axios.get(pdfUrl, {
        responseType: 'arraybuffer',
        timeout: 30000,
        maxRedirects: 5,
        headers: {
          'User-Agent': 'Mozilla/5.0 (compatible; Paper Master Bot 1.0)',
          'Accept': 'application/pdf'
        },
        validateStatus: (status) => status >= 200 && status < 400
      });

      // Check response headers
      const contentType = response.headers['content-type'] || '';
      console.log(`Response Content-Type: ${contentType}`);
      console.log(`Response status: ${response.status}`);
      
      const pdfBuffer = Buffer.from(response.data);
      console.log(`PDF download SUCCESS: ${pdfBuffer.length} bytes`);
      
      // Validate PDF content
      if (pdfBuffer.length < 100) {
        console.error(`PDF file too small (${pdfBuffer.length} bytes), likely not a valid PDF`);
        const contentPreview = pdfBuffer.toString('utf-8', 0, Math.min(200, pdfBuffer.length));
        console.error(`Content preview: ${contentPreview}`);
        console.error(`Content-Type was: ${contentType}`);
        return null;
      }
      
      // Check PDF magic number (%PDF)
      const pdfHeader = pdfBuffer.toString('utf-8', 0, 4);
      if (pdfHeader !== '%PDF') {
        console.error(`Invalid PDF header: Expected "%PDF", got "${pdfHeader}"`);
        const contentPreview = pdfBuffer.toString('utf-8', 0, Math.min(500, pdfBuffer.length));
        console.error(`Content preview: ${contentPreview}`);
        console.error(`Content-Type was: ${contentType}`);
        console.error(`This might be an HTML error page instead of a PDF`);
        return null;
      }
      
      console.log(`PDF validation SUCCESS: Valid PDF file (${pdfBuffer.length} bytes)`);
      return pdfBuffer;
      
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      console.error('PDF download FAILED:', errorMessage);
      
      // Log detailed error information
      if (error && typeof error === 'object' && 'response' in error) {
        const axiosError = error as any;
        console.error('Response status:', axiosError.response?.status);
        console.error('Response headers:', axiosError.response?.headers);
        if (axiosError.response?.data) {
          const errorData = Buffer.from(axiosError.response.data).toString('utf-8', 0, 500);
          console.error('Response data preview:', errorData);
        }
      }
      
      return null;
    }
  }

  /**
   * Test processing PDF with GROBID
   */
  async testGrobidProcessing(pdfBuffer: Buffer): Promise<string | null> {
    try {
      console.log('Testing GROBID PDF processing...');

      const formData = new FormData();
      formData.append('input', pdfBuffer, {
        filename: 'test_paper.pdf',
        contentType: 'application/pdf'
      });

      console.log('Sending PDF to GROBID...');
      
      const response = await axios.post(
        `${this.grobidBaseUrl}/api/processFulltextDocument`,
        formData,
        {
          headers: {
            ...formData.getHeaders(),
          },
          timeout: 120000, // 2 minutes timeout for GROBID processing
        }
      );

      console.log(`GROBID processing SUCCESS: ${response.data.length} characters of TEI XML`);
      return response.data;
      
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      console.error('GROBID processing FAILED:', errorMessage);
      if (error && typeof error === 'object' && 'response' in error) {
        const axiosError = error as any;
        console.error('Response status:', axiosError.response?.status);
        console.error('Response data:', axiosError.response?.data);
      }
      return null;
    }
  }

  /**
   * Test parsing TEI XML structure
   */
  async testTeiXmlParsing(teiXml: string): Promise<{
    hasReferences: boolean;
    referenceCount: number;
    hasCitations: boolean;
    citationCount: number;
    sections: string[];
  }> {
    try {
      console.log('Testing TEI XML parsing...');
      
      const $ = cheerio.load(teiXml, { xmlMode: true });
      
      // Test bibliography extraction
      const biblStructs = $('listBibl biblStruct');
      const referenceCount = biblStructs.length;
      
      console.log(`Found ${referenceCount} bibliography entries`);
      
      // Test citation extraction
      const citationRefs = $('ref[type="bibr"]');
      const citationCount = citationRefs.length;
      
      console.log(`Found ${citationCount} citation references in text`);
      
      // Test section extraction
      const sections = $('div[type="section"] head').map((_, el) => $(el).text().trim()).get();
      
      console.log(`Found ${sections.length} sections:`, sections);
      
      return {
        hasReferences: referenceCount > 0,
        referenceCount,
        hasCitations: citationCount > 0,
        citationCount,
        sections
      };
      
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      console.error('TEI XML parsing FAILED:', errorMessage);
      return {
        hasReferences: false,
        referenceCount: 0,
        hasCitations: false,
        citationCount: 0,
        sections: []
      };
    }
  }

  /**
   * Complete test pipeline for an arXiv URL
   */
  async testCompleteWorkflow(arxivUrl: string): Promise<{
    success: boolean;
    steps: {
      grobidConnection: boolean;
      pdfDownload: boolean;
      grobidProcessing: boolean;
      teiParsing: boolean;
    };
    results?: {
      referenceCount: number;
      citationCount: number;
      sections: string[];
    };
    error?: string;
  }> {
    console.log(`\n=== Testing Complete GROBID Workflow ===`);
    console.log(`Input URL: ${arxivUrl}`);
    
    const results = {
      success: false,
      steps: {
        grobidConnection: false,
        pdfDownload: false,
        grobidProcessing: false,
        teiParsing: false
      }
    };

    try {
      // Step 1: Test GROBID connection
      console.log('\n--- Step 1: Testing GROBID Connection ---');
      results.steps.grobidConnection = await this.testGrobidConnection();
      
      if (!results.steps.grobidConnection) {
        return { ...results, error: 'GROBID service not available' };
      }

      // Step 2: Test PDF download
      console.log('\n--- Step 2: Testing PDF Download ---');
      const pdfBuffer = await this.testPdfDownload(arxivUrl);
      results.steps.pdfDownload = pdfBuffer !== null;
      
      if (!pdfBuffer) {
        return { ...results, error: 'Failed to download PDF' };
      }

      // Step 3: Test GROBID processing
      console.log('\n--- Step 3: Testing GROBID Processing ---');
      const teiXml = await this.testGrobidProcessing(pdfBuffer);
      results.steps.grobidProcessing = teiXml !== null;
      
      if (!teiXml) {
        return { ...results, error: 'Failed to process PDF with GROBID' };
      }

      // Step 4: Test TEI XML parsing
      console.log('\n--- Step 4: Testing TEI XML Parsing ---');
      const parseResults = await this.testTeiXmlParsing(teiXml);
      results.steps.teiParsing = parseResults.hasReferences || parseResults.hasCitations;

      console.log('\n=== Test Results Summary ===');
      console.log(`‚úÖ GROBID Connection: ${results.steps.grobidConnection}`);
      console.log(`‚úÖ PDF Download: ${results.steps.pdfDownload}`);
      console.log(`‚úÖ GROBID Processing: ${results.steps.grobidProcessing}`);
      console.log(`‚úÖ TEI Parsing: ${results.steps.teiParsing}`);
      console.log(`üìö References: ${parseResults.referenceCount}`);
      console.log(`üîó Citations: ${parseResults.citationCount}`);
      console.log(`üìÑ Sections: ${parseResults.sections.length}`);

      return {
        success: true,
        steps: results.steps,
        results: {
          referenceCount: parseResults.referenceCount,
          citationCount: parseResults.citationCount,
          sections: parseResults.sections
        }
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      console.error('\nWorkflow FAILED:', errorMessage);
      return { ...results, error: errorMessage };
    }
  }

  /**
   * Quick test with a sample reference extraction
   */
  async extractSampleReferences(teiXml: string): Promise<Array<{
    id: string;
    title: string;
    authors: string[];
    year: string;
  }>> {
    const $ = cheerio.load(teiXml, { xmlMode: true });
    const references: Array<{ id: string; title: string; authors: string[]; year: string }> = [];

    $('listBibl biblStruct').each((_, element) => {
      const $ref = $(element);
      const refId = $ref.attr('xml:id') || '';
      
      const title = $ref.find('analytic title[type="main"], monogr title').first().text().trim();
      // Extract all authors from bibliography reference
      // GROBID structure: <author><persName><forename>...</forename><surname>...</surname></persName></author>
      const authors = $ref.find('author').map((_, authorEl) => {
        const $author = $(authorEl);
        const persName = $author.find('persName').first();
        if (persName.length > 0) {
          // Handle multiple forenames (e.g., "Quoc V." -> "Quoc V.")
          const allForenames = persName.find('forename').map((_, fn) => $(fn).text().trim()).get().join(' ');
          const surname = persName.find('surname').text().trim();
          return `${allForenames} ${surname}`.trim();
        }
        // Fallback to direct text
        return $author.text().trim();
      }).get().filter(name => name.length > 0);
      
      const year = $ref.find('date[when]').attr('when') || 
                   $ref.find('date').text().match(/\d{4}/)?.[0] || '';

      if (title) {
        references.push({ id: refId, title, authors, year });
      }
    });

    return references.slice(0, 5); // Return first 5 for testing
  }

  /**
   * Extract citations with context from a paper
   */
  /**
   * Remove duplicate citations based on title, authors, and year
   * Normalizes titles and author lists for comparison
   */
  private removeDuplicateCitationsByContent(citations: Array<{
    id: string;
    title?: string;
    authors?: string[];
    year?: string;
    context: string;
    contextBefore: string;
    contextAfter: string;
    section?: string;
  }>): Array<{
    id: string;
    title?: string;
    authors?: string[];
    year?: string;
    context: string;
    contextBefore: string;
    contextAfter: string;
    section?: string;
  }> {
    const normalizeTitle = (title: string | undefined): string => {
      if (!title) return '';
      return title
        .trim()
        .toLowerCase()
        .replace(/\s+/g, ' ') // Replace multiple spaces with single space
        .replace(/[^\w\s]/g, '') // Remove punctuation for comparison
        .trim();
    };

    const normalizeAuthors = (authors: string[] | undefined): string[] => {
      if (!authors || authors.length === 0) return [];
      return authors
        .map(a => a.trim().toLowerCase())
        .filter(a => a.length > 0)
        .sort(); // Sort to handle different orders
    };

    const areAuthorsSimilar = (authors1: string[] | undefined, authors2: string[] | undefined): boolean => {
      const normalized1 = normalizeAuthors(authors1);
      const normalized2 = normalizeAuthors(authors2);
      
      // If both have no authors, consider them similar
      if (normalized1.length === 0 && normalized2.length === 0) {
        return true;
      }
      
      // If one has authors and the other doesn't, they're not similar
      if (normalized1.length === 0 || normalized2.length === 0) {
        return false;
      }
      
      // Check if all authors match (exact match)
      if (normalized1.length === normalized2.length && 
          normalized1.every((a, i) => a === normalized2[i])) {
        return true;
      }
      
      // Check if they share at least 2 authors (for papers with many authors)
      // Or if one list is a subset of the other (handles cases where one has fewer authors listed)
      const commonAuthors = normalized1.filter(a => normalized2.includes(a));
      const minLength = Math.min(normalized1.length, normalized2.length);
      if (commonAuthors.length >= Math.min(2, minLength) || 
          commonAuthors.length === minLength) {
        return true;
      }
      
      return false;
    };

    const isDuplicate = (c1: typeof citations[0], c2: typeof citations[0]): boolean => {
      // Compare normalized titles
      const title1 = normalizeTitle(c1.title);
      const title2 = normalizeTitle(c2.title);
      
      // If both titles are empty, skip title comparison
      if (title1 === '' && title2 === '') {
        // If both have no title, we can't reliably compare, skip
        return false;
      }
      
      if (title1 !== title2) {
        return false;
      }
      
      // If titles match, compare years (if both have years, they must match)
      if (c1.year && c2.year && c1.year !== c2.year) {
        return false; // Different years, not a duplicate
      }
      
      // Compare authors
      return areAuthorsSimilar(c1.authors, c2.authors);
    };

    const uniqueCitations: typeof citations = [];
    
    for (const citation of citations) {
      // Check if this citation is a duplicate of any already in uniqueCitations
      let foundDuplicate = false;
      let duplicateIndex = -1;
      
      for (let i = 0; i < uniqueCitations.length; i++) {
        if (isDuplicate(citation, uniqueCitations[i])) {
          foundDuplicate = true;
          duplicateIndex = i;
          break;
        }
      }
      
      if (foundDuplicate && duplicateIndex >= 0) {
        // Compare and keep the one with more information
        const existing = uniqueCitations[duplicateIndex];
        const shouldReplace = 
          (citation.authors && citation.authors.length > 0 && (!existing.authors || citation.authors.length > existing.authors.length)) ||
          (citation.year && !existing.year) ||
          (citation.context && citation.context.length > (existing.context?.length || 0));
        
        if (shouldReplace) {
          uniqueCitations[duplicateIndex] = citation;
          console.log(`üîÑ Replacing duplicate citation "${citation.title?.substring(0, 50) || citation.id}..." with more complete version`);
        } else {
          console.log(`üîÑ Skipping duplicate citation "${citation.title?.substring(0, 50) || citation.id}..."`);
        }
      } else {
        // New unique citation
        uniqueCitations.push(citation);
      }
    }
    
    console.log(`‚úÖ Removed ${citations.length - uniqueCitations.length} duplicate citations (${uniqueCitations.length} unique remaining)`);
    
    return uniqueCitations;
  }

  async extractCitationsWithContext(arxivUrl: string): Promise<{
    success: boolean;
    paperTitle?: string;
    citations: Array<{
      id: string;
      title?: string;
      authors?: string[];
      year?: string;
      context: string;
      contextBefore: string;
      contextAfter: string;
      section?: string;
    }>;
    error?: string;
  }> {
    try {
      console.log(`\n=== Extracting Citations with Context ===`);
      console.log(`Input URL: ${arxivUrl}`);

      // Step 1: Download PDF
      const pdfBuffer = await this.testPdfDownload(arxivUrl);
      if (!pdfBuffer) {
        return { success: false, citations: [], error: 'Failed to download PDF' };
      }

      // Step 2: Process with GROBID
      const teiXml = await this.testGrobidProcessing(pdfBuffer);
      if (!teiXml) {
        return { success: false, citations: [], error: 'Failed to process PDF with GROBID' };
      }

      // Step 3: Parse TEI XML for citations with context
      const $ = cheerio.load(teiXml, { xmlMode: true });
      
      // Extract paper title
      const paperTitle = $('title[level="a"]').first().text().trim() || 
                        $('titleStmt title').first().text().trim();

      console.log(`Paper title: ${paperTitle}`);

      // Extract bibliography entries first
      const bibliographyMap = new Map<string, any>();
      $('listBibl biblStruct').each((_, biblStruct) => {
        const $bibl = $(biblStruct);
        const xmlId = $bibl.attr('xml:id');
        
        if (xmlId) {
          const title = $bibl.find('title[level="a"]').first().text().trim() ||
                       $bibl.find('title').first().text().trim();
          
          // Extract all authors from bibliography entry
          // GROBID structure: <author><persName><forename>...</forename><surname>...</surname></persName></author>
          const authors = $bibl.find('author').map((_, authorEl) => {
            const $author = $(authorEl);
            const persName = $author.find('persName').first();
            if (persName.length > 0) {
              // Handle multiple forenames
              const allForenames = persName.find('forename').map((_, fn) => $(fn).text().trim()).get().join(' ');
              const surname = persName.find('surname').text().trim();
              return `${allForenames} ${surname}`.trim();
            }
            // Fallback to direct text
            return $author.text().trim();
          }).get().filter(name => name.length > 0);

          const year = $bibl.find('date').attr('when') || 
                      $bibl.find('date').text().trim();

          bibliographyMap.set(xmlId, {
            id: xmlId,
            title,
            authors,
            year
          });
        }
      });

      console.log(`Found ${bibliographyMap.size} bibliography entries`);

      // Extract citations in context
      const citations: Array<{
        id: string;
        title?: string;
        authors?: string[];
        year?: string;
        context: string;
        contextBefore: string;
        contextAfter: string;
        section?: string;
      }> = [];

      // Find all citation references in the text
      $('ref[type="bibr"]').each((_, ref) => {
        const $ref = $(ref);
        const target = $ref.attr('target');
        
        if (target && target.startsWith('#')) {
          const bibId = target.substring(1);
          const bibData = bibliographyMap.get(bibId);
          
          if (bibData) {
            // Get the containing paragraph or sentence
            const $paragraph = $ref.closest('p, s');
            const fullText = $paragraph.text().trim();
            
            // Get context around the citation
            const refText = $ref.text().trim();
            const refIndex = fullText.indexOf(refText);
            
            let contextBefore = '';
            let contextAfter = '';
            
            if (refIndex !== -1) {
              const contextLength = 200; // characters before/after
              const start = Math.max(0, refIndex - contextLength);
              const end = Math.min(fullText.length, refIndex + refText.length + contextLength);
              
              contextBefore = fullText.substring(start, refIndex).trim();
              contextAfter = fullText.substring(refIndex + refText.length, end).trim();
            }

            // Find the section this citation is in
            const $section = $ref.closest('div[type="section"]');
            const sectionTitle = $section.find('head').first().text().trim();

            citations.push({
              id: bibId,
              title: bibData.title,
              authors: bibData.authors,
              year: bibData.year,
              context: fullText,
              contextBefore,
              contextAfter,
              section: sectionTitle
            });
          }
        }
      });

      console.log(`Extracted ${citations.length} citations with context`);

      // Remove duplicates based on title, authors, and year
      const uniqueCitations = this.removeDuplicateCitationsByContent(citations);

      return {
        success: true,
        paperTitle,
        citations: uniqueCitations
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      console.error('Citation extraction failed:', errorMessage);
      return {
        success: false,
        citations: [],
        error: errorMessage
      };
    }
  }

  /**
   * Extract semantic relationships from a paper using GROBID analysis
   */
  async extractSemanticRelationships(paper: Paper): Promise<{
    citedPapers: Array<{
      paper: Paper;
      relationship: string;
      confidence: number;
      context: string;
    }>;
  }> {
    try {
      console.log(`Extracting semantic relationships for: ${paper.title}`);

      // For now, return empty relationships
      // TODO: Implement full semantic extraction using GROBID
      return {
        citedPapers: []
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      console.error('Semantic relationship extraction failed:', errorMessage);
      return {
        citedPapers: []
      };
    }
  }

  /**
   * ÊèêÂèñÂ∏∂‰∏ä‰∏ãÊñáÁöÑÂºïÁî®‰ø°ÊÅØÔºàÂÉÖÈôê Related Work Âíå Introduction ÈÉ®ÂàÜÔºâ
   * Êñ∞Â¢ûÔºöËøîÂõû TEI XML Áî®ÊñºÊ∑±Â∫¶ÂàÜÊûê
   */
  async extractCitationsWithContextFiltered(arxivUrl: string): Promise<{
    success: boolean;
    paperTitle?: string;
    paperAuthors?: string[];
    paperAbstract?: string;
    paperVenue?: string;
    paperYear?: string;
    paperCitationCount?: number; // Êñ∞Â¢ûÔºöÂºïÁî®Ê¨°Êï∏
    teiXml?: string; // Êñ∞Â¢ûÔºöËøîÂõû TEI XML
    citations: Array<{
      id: string;
      title?: string;
      authors?: string[];
      year?: string;
      context: string;
      contextBefore: string;
      contextAfter: string;
      section?: string;
    }>;
    totalSections?: string[];
    filteredSections?: string[];
    error?: string;
  }> {
    try {
      console.log(`\n=== Extracting Citations (Related Work & Introduction Only) ===`);
      console.log(`Input URL: ${arxivUrl}`);

      // Step 1: Download PDF
      const pdfBuffer = await this.testPdfDownload(arxivUrl);
      if (!pdfBuffer) {
        return { success: false, citations: [], error: 'Failed to download PDF' };
      }

      // Step 2: Process with GROBID
      const teiXml = await this.testGrobidProcessing(pdfBuffer);
      if (!teiXml) {
        return { success: false, citations: [], error: 'Failed to process PDF with GROBID' };
      }

      // Step 3: Parse TEI XML for citations with section filtering
      // GROBID uses TEI namespace, but cheerio doesn't handle namespaces well
      // Remove namespace declarations for easier parsing
      const teiXmlNoNs = teiXml.replace(/xmlns(?::[^=]*)?="[^"]*"/g, '');
      const $ = cheerio.load(teiXmlNoNs, { xmlMode: true });
      
      // Debug: Print TEI XML structure for author extraction
      console.log(`\n=== TEI XML Debug Info ===`);
      console.log(`üìÑ TEI XML length: ${teiXml.length} characters`);
      
      // Save TEI XML to file for detailed inspection
      const debugDir = path.join(__dirname, '../../debug');
      if (!fs.existsSync(debugDir)) {
        fs.mkdirSync(debugDir, { recursive: true });
      }
      
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      const filename = `tei_xml_${timestamp}.xml`;
      const filepath = path.join(debugDir, filename);
      
      try {
        fs.writeFileSync(filepath, teiXml, 'utf8');
        console.log(`üìÅ TEI XML saved to: ${filepath}`);
      } catch (error) {
        console.warn(`‚ö†Ô∏è  Could not save TEI XML to file:`, error);
      }
      
      // Print the first 2000 characters of TEI XML to see structure
      console.log(`üìã TEI XML Header (first 2000 chars):`);
      console.log(teiXml.substring(0, 2000));
      console.log(`...(truncated)`);
      
      // Check for different author-related elements
      console.log(`\nüìù Author-related elements found:`);
      console.log(`   - <author> elements: ${$('author').length}`);
      console.log(`   - <persName> elements: ${$('persName').length}`);
      console.log(`   - <name> elements: ${$('name').length}`);
      console.log(`   - <fileDesc> elements: ${$('fileDesc').length}`);
      console.log(`   - <titleStmt> elements: ${$('titleStmt').length}`);
      
      if ($('author').length > 0) {
        console.log(`üìã First <author> element:`, $('author').first().html());
      }
      if ($('persName').length > 0) {
        console.log(`üìã First <persName> element:`, $('persName').first().html());
      }
      
      // Extract paper title
      let paperTitle = $('title[level="a"]').first().text().trim() || 
                        $('titleStmt title').first().text().trim();

      console.log(`Paper title: ${paperTitle}`);

      // Extract paper authors - only from main paper, not from references
      let paperAuthors: string[] = [];
      
      // Extract publication year (initialize early for Semantic Scholar override)
      let paperYear = $('publicationStmt date').attr('when') || 
                       $('imprint date').attr('when') ||
                       $('date').attr('when');
      
      // Use the most specific selector that targets only the main paper authors
      // Based on GROBID TEI XML structure: teiHeader > fileDesc > sourceDesc > biblStruct > analytic > author
      // GROBID stores each author as: <author><persName><forename>...</forename><surname>...</surname></persName></author>
      // Note: After removing namespaces, we can use simple selectors
      const authorSelectors = [
        'teiHeader > fileDesc > sourceDesc > biblStruct > analytic > author', // Most specific - main paper only
        'fileDesc > sourceDesc > biblStruct > analytic > author', // Alternative without teiHeader
        'sourceDesc > biblStruct > analytic > author', // More general but still avoids references
        'biblStruct > analytic > author', // Even more general
        'analytic > author', // Most general but should work
      ];
      
      for (const selector of authorSelectors) {
        if (paperAuthors.length === 0) {
          console.log(`üîç Trying author selector: "${selector}"`);
          const authorElements = $(selector);
          console.log(`   Found ${authorElements.length} <author> elements with this selector`);
          
          paperAuthors = authorElements.map((_, authorEl) => {
            const $author = $(authorEl);
            // GROBID structure: <author><persName><forename>First</forename><surname>Last</surname></persName></author>
            const persName = $author.find('persName').first();
            if (persName.length > 0) {
              // Handle multiple forenames (e.g., "Quoc V." -> "Quoc V.")
              // Also handle middle names (type="middle")
              const allForenames = persName.find('forename').map((_, fn) => {
                const $fn = $(fn);
                return $fn.text().trim();
              }).get().filter(fn => fn && fn.length > 0).join(' ');
              
              const surname = persName.find('surname').text().trim();
              const fullName = `${allForenames} ${surname}`.trim();
              
              // Skip if name looks invalid (e.g., organization names incorrectly parsed)
              if (fullName.length > 0 && 
                  fullName !== 'Google Brain' && 
                  !fullName.match(/^(Google|Facebook|Microsoft|Apple|Amazon)\s+(Brain|Research|AI|Lab)/i)) {
                return fullName;
              }
            }
            // Fallback: try direct text extraction (but filter out invalid names)
            const directText = $author.text().trim();
            if (directText.length > 0 && 
                directText !== 'Google Brain' && 
                !directText.match(/^(Google|Facebook|Microsoft|Apple|Amazon)\s+(Brain|Research|AI|Lab)/i)) {
              // Basic validation: should have at least 2 words for a valid name
              const parts = directText.split(/\s+/).filter(p => p.length > 0);
              if (parts.length >= 2) {
                return directText;
              }
            }
            return '';
          }).get().filter(name => {
            // Final filter: remove empty, single-word, or obviously invalid names
            if (!name || name.length === 0) return false;
            const parts = name.split(/\s+/).filter(p => p.length > 0);
            if (parts.length < 2) return false;
            // Filter out organization names that might be incorrectly parsed as authors
            if (name.match(/^(Google|Facebook|Microsoft|Apple|Amazon)\s+(Brain|Research|AI|Lab)/i)) return false;
            return true;
          });
          
          if (paperAuthors.length > 0) {
            console.log(`‚úÖ Found ${paperAuthors.length} authors with selector "${selector}"`);
            console.log(`   First 3: ${paperAuthors.slice(0, 3).join(', ')}`);
            console.log(`   Last 3: ${paperAuthors.slice(-3).join(', ')}`);
            if (paperAuthors.length > 6) {
              console.log(`   Full list: ${paperAuthors.join(', ')}`);
            }
            break;
          }
        }
      }
      
      // If still no authors found, try more specific fallback methods
      if (paperAuthors.length === 0) {
        console.log(`‚ö†Ô∏è  No authors found with standard selectors, trying fallback methods...`);
        // Try to get authors only from the main document (not from references)
        const mainDocAuthors = $('teiHeader').find('author');
        console.log(`   Found ${mainDocAuthors.length} <author> elements in teiHeader`);
        if (mainDocAuthors.length > 0) {
          paperAuthors = mainDocAuthors.map((_, authorEl) => {
            const $author = $(authorEl);
            const persName = $author.find('persName').first();
            if (persName.length > 0) {
              const allForenames = persName.find('forename').map((_, fn) => $(fn).text().trim()).get().join(' ');
              const surname = persName.find('surname').text().trim();
              return `${allForenames} ${surname}`.trim();
            }
            return $author.text().trim();
          }).get().filter(name => name.length > 0);
          console.log(`‚úÖ Found ${paperAuthors.length} authors in teiHeader fallback`);
          console.log(`   Authors: ${paperAuthors.join(', ')}`);
        }
      }
      
      // Debug info if still no authors
      if (paperAuthors.length === 0) {
        console.warn(`‚ö†Ô∏è  No authors found with any selector. TEI structure might be different.`);
        // Debug: print some TEI structure info (excluding reference section)
        const teiHeaderAuthors = $('teiHeader author').length;
        const sourceDescAuthors = $('sourceDesc author').length;
        const backAuthors = $('back author').length; // This should show reference authors
        console.log(`üìã TEI author elements - teiHeader: ${teiHeaderAuthors}, sourceDesc: ${sourceDescAuthors}, back/references: ${backAuthors}`);
        
        if ($('teiHeader author').length > 0) {
          console.log(`üìã First teiHeader author element:`, $('teiHeader author').first().html());
        }
      }

      // Extract paper abstract - remove citation references
      let paperAbstract = $('profileDesc abstract p').clone().children('ref').remove().end().text().trim() || 
                         $('abstract p').clone().children('ref').remove().end().text().trim() ||
                         $('abstract').clone().children('ref').remove().end().text().trim();
      
      // Clean up any remaining citation markers like [1], (Smith et al., 2020), etc.
      paperAbstract = paperAbstract
        .replace(/\[\d+(?:,\s*\d+)*\]/g, '') // Remove [1], [1,2,3] style citations
        .replace(/\(\s*[A-Za-z]+(?:\s+et\s+al\.?)?,?\s*\d{4}\s*\)/g, '') // Remove (Author et al., 2020) style citations
        .replace(/\(\s*\d{4}\s*\)/g, '') // Remove (2020) style citations
        .replace(/\s+/g, ' ') // Normalize whitespace
        .trim();

      // Extract publication info (venue) - enhanced with Semantic Scholar lookup
      let paperVenue = '';
      let paperCitationCount: number | undefined = undefined;
      let venueSource = 'TEI XML';
      
      // First try to get venue from main paper's monogr section (most specific)
      const mainPaperVenue = $('teiHeader > fileDesc > sourceDesc > biblStruct > monogr title').text().trim();
      if (mainPaperVenue) {
        paperVenue = mainPaperVenue;
        venueSource = 'TEI XML (main paper)';
      } else {
        // Fallback: try publicationStmt publisher
        const publisher = $('publicationStmt publisher').text().trim();
        if (publisher && publisher !== '') {
          paperVenue = publisher;
          venueSource = 'TEI XML (publisher)';
        } else {
          // Check if this is an arXiv paper and try Semantic Scholar lookup
          const arxivId = $('idno[type="arXiv"]').text().trim();
          if (arxivId) {
            console.log(`üîç Found arXiv ID: ${arxivId}, querying Semantic Scholar for venue and citations...`);
            
            try {
              // Query Semantic Scholar for complete paper information
              const semanticScholarData = await SemanticScholarService.getEnhancedVenueInfo(arxivId);
              
              // Always get citation count from Semantic Scholar
              paperCitationCount = semanticScholarData.citationCount;
              
              // Use Semantic Scholar data for venue
              if (semanticScholarData.venue && !semanticScholarData.isPreprint) {
                paperVenue = semanticScholarData.venue;
                venueSource = `Semantic Scholar (${semanticScholarData.venueType})`;
                
                console.log(`‚úÖ Found published venue in Semantic Scholar:
                  - Venue: "${semanticScholarData.venue}"
                  - Type: ${semanticScholarData.venueType}
                  - Publication Date: ${semanticScholarData.publicationDate}
                  - Citations: ${semanticScholarData.citationCount}
                  - Publication Types: ${semanticScholarData.publicationTypes?.join(', ')}`);
              } else {
                paperVenue = 'arXiv preprint';
                venueSource = 'arXiv (preprint)';
                console.log(`üìÑ Paper is still a preprint (${semanticScholarData.citationCount || 0} citations)`);
              }

              // üöÄ NEW: Override title, authors, year with Semantic Scholar data if available
              // BUT: Only override authors if GROBID didn't extract any authors, because GROBID extracts ALL authors
              // while Semantic Scholar might only return a subset (especially in search results)
              if (semanticScholarData.title && semanticScholarData.title.trim()) {
                paperTitle = semanticScholarData.title;
                console.log(`‚úÖ Using Semantic Scholar title: "${paperTitle}"`);
              }
              
              // Only override authors if GROBID didn't extract any authors
              // GROBID extracts complete author list from PDF, which is more reliable
              if (paperAuthors.length === 0 && semanticScholarData.authors && semanticScholarData.authors.length > 0) {
                paperAuthors = semanticScholarData.authors;
                console.log(`‚úÖ Using Semantic Scholar authors (GROBID had none): ${paperAuthors.length} authors`);
              } else if (paperAuthors.length > 0 && semanticScholarData.authors && semanticScholarData.authors.length > 0) {
                // Log comparison but keep GROBID authors (they should be complete)
                console.log(`üìä Author count comparison - GROBID: ${paperAuthors.length}, Semantic Scholar: ${semanticScholarData.authors.length}`);
                console.log(`üìä Keeping GROBID authors (complete list from PDF), Semantic Scholar may have truncated list`);
                if (semanticScholarData.authors.length > paperAuthors.length) {
                  // Rare case: Semantic Scholar has more authors than GROBID
                  console.warn(`‚ö†Ô∏è  Semantic Scholar has MORE authors (${semanticScholarData.authors.length}) than GROBID (${paperAuthors.length}). This is unusual.`);
                  console.warn(`    GROBID authors: ${paperAuthors.slice(0, 5).join(', ')}${paperAuthors.length > 5 ? '...' : ''}`);
                  console.warn(`    Semantic Scholar authors: ${semanticScholarData.authors.slice(0, 5).join(', ')}${semanticScholarData.authors.length > 5 ? '...' : ''}`);
                  // In this case, prefer Semantic Scholar as it might have more complete data
                  paperAuthors = semanticScholarData.authors;
                  console.log(`‚úÖ Using Semantic Scholar authors (more complete): ${paperAuthors.length} authors`);
                }
              }
              
              if (semanticScholarData.year) {
                paperYear = semanticScholarData.year.toString();
                console.log(`‚úÖ Using Semantic Scholar year: ${paperYear}`);
              }
            } catch (error) {
              console.warn(`‚ö†Ô∏è  Failed to query Semantic Scholar:`, error);
              paperVenue = 'arXiv preprint';
              venueSource = 'arXiv (fallback)';
            }
          } else {
            // Last resort: check for journal/conference in various places, but avoid references
            paperVenue = $('fileDesc > sourceDesc > biblStruct > monogr title').text().trim() || 
                        $('sourceDesc > biblStruct > monogr title').first().text().trim() || 
                        '';
            venueSource = 'TEI XML (fallback)';
            
            // If no arXiv ID but we have title/authors/year, try Semantic Scholar query
            if (!paperCitationCount && paperTitle && paperAuthors.length > 0) {
              console.log(`üîç No arXiv ID found, trying Semantic Scholar query by title+authors+year...`);
              try {
                const searchResult = await SemanticScholarService.queryByTitleAndAuthors(
                  paperTitle,
                  paperAuthors,
                  paperYear
                );
                if (searchResult.success && searchResult.data?.citationCount !== undefined) {
                  paperCitationCount = searchResult.data.citationCount;
                  console.log(`‚úÖ Found citation count via title search: ${paperCitationCount}`);
                  
                  // Also update venue if available
                  if (searchResult.data.venue && !paperVenue) {
                    paperVenue = searchResult.data.venue;
                    venueSource = 'Semantic Scholar (title search)';
                  }
                }
              } catch (error) {
                console.warn(`‚ö†Ô∏è  Failed to query Semantic Scholar by title:`, error);
              }
            }
          }
        }
      }
      
      console.log(`üìç Paper venue and citation extraction:
        - Main paper monogr title: "${mainPaperVenue}"
        - Publisher: "${$('publicationStmt publisher').text().trim()}"
        - ArXiv ID: "${$('idno[type="arXiv"]').text().trim()}"
        - Final venue: "${paperVenue}" (source: ${venueSource})
        - Citation count: ${paperCitationCount || 'unknown'}
        - Citation count type: ${typeof paperCitationCount}`);

      console.log(`üîç [CITATION DEBUG] Final citation result: ${JSON.stringify({
        paperCitationCount: paperCitationCount,
        citationCountType: typeof paperCitationCount,
        isUndefined: paperCitationCount === undefined,
        isNull: paperCitationCount === null
      })}`);

      // Use year already extracted earlier (overridden by Semantic Scholar if available)
      // paperYear is already declared above

      console.log(`Paper authors: ${paperAuthors.join(', ')}`);
      console.log(`Paper abstract: ${paperAbstract.substring(0, 100)}...`);
      console.log(`Paper venue: ${paperVenue}`);
      console.log(`Paper year: ${paperYear}`);

      // Extract all section titles for debugging - try multiple selectors
      let allSections = $('div[type="section"] head').map((_, el) => $(el).text().trim()).get();
      
      // If no sections found with first selector, try alternatives
      if (allSections.length === 0) {
        allSections = $('div head').map((_, el) => $(el).text().trim()).get();
      }
      
      if (allSections.length === 0) {
        allSections = $('head').map((_, el) => $(el).text().trim()).get();
      }
      
      if (allSections.length === 0) {
        // Try to find any text that looks like section headers
        allSections = $('p').filter((_, el) => {
          const text = $(el).text().trim();
          return text.length < 100 && /^[A-Z][a-zA-Z\s]{3,50}$/.test(text);
        }).map((_, el) => $(el).text().trim()).get().slice(0, 20); // Limit to first 20
      }
      
      console.log(`All sections found: ${allSections.join(', ')}`);

      // Define target sections (case-insensitive patterns) - Êâ©Â±ïÂåπÈÖçÊ®°Âºè
      const targetSectionPatterns = [
        // Introduction Áõ∏ÂÖ≥Âèò‰Ωì
        /^introduction$/i,
        /^introduction\s+and\s+motivation$/i,
        /^introduction\s+and\s+overview$/i,
        /^introduction\s+and\s+background$/i,
        /^overview$/i,
        /^motivation$/i,
        /^motivation\s+and\s+introduction$/i,
        /^background$/i,
        /^background\s+and\s+motivation$/i,
        
        // Related Work Áõ∏ÂÖ≥Âèò‰Ωì
        /^related\s+work$/i,
        /^related\s+works$/i,
        /^literature\s+review$/i,
        /^literature\s+reviews$/i,
        /^literature$/i,
        /^previous\s+work$/i,
        /^previous\s+works$/i,
        /^prior\s+work$/i,
        /^prior\s+works$/i,
        /^related\s+research$/i,
        /^related\s+studies$/i,
        /^state\s+of\s+the\s+art$/i,
        /^state-of-the-art$/i,
        /^sota$/i,
        /^existing\s+work$/i,
        /^existing\s+works$/i,
        /^related\s+work\s+and\s+background$/i,
        /^background\s+and\s+related\s+work$/i,
        /^related\s+work\s+and\s+motivation$/i,
        /^related\s+work\s+and\s+literature\s+review$/i,
        /^literature\s+review\s+and\s+related\s+work$/i,
        /^survey$/i,
        /^survey\s+of\s+related\s+work$/i,
        /^review\s+of\s+related\s+work$/i,
        /^review$/i,
        
        // ÂÖ∂‰ªñÂèØËÉΩÂåÖÂê´ÂºïÁî®ÁöÑÁ´†ËäÇ
        /^discussion\s+of\s+related\s+work$/i,
        /^comparison\s+with\s+related\s+work$/i,
        /^comparison$/i,
        /^related\s+approaches$/i,
        /^alternative\s+approaches$/i,
        /^other\s+approaches$/i,
        /^related\s+methods$/i,
        /^related\s+techniques$/i
      ];

      // ÊîπËøõÁöÑÂåπÈÖçÂáΩÊï∞ÔºöÊîØÊåÅÈÉ®ÂàÜÂåπÈÖçÂíåÊ®°Á≥äÂåπÈÖç
      const matchSection = (sectionTitle: string): boolean => {
        const normalizedTitle = sectionTitle.trim().toLowerCase();
        
        // 1. Á≤æÁ°ÆÊ®°ÂºèÂåπÈÖç
        if (targetSectionPatterns.some(pattern => pattern.test(sectionTitle))) {
          return true;
        }
        
        // 2. ÈÉ®ÂàÜÂåπÈÖçÔºöÊ£ÄÊü•Ê†áÈ¢òÊòØÂê¶ÂåÖÂê´ÂÖ≥ÈîÆËØç
        const keywords = [
          'introduction', 'related work', 'related works', 'literature review',
          'background', 'previous work', 'prior work', 'motivation',
          'overview', 'survey', 'review', 'state of the art', 'sota'
        ];
        
        for (const keyword of keywords) {
          if (normalizedTitle.includes(keyword.toLowerCase())) {
            // Á°Æ‰øù‰∏çÊòØÂÖ∂‰ªñÁ´†ËäÇÔºàÂ¶Ç "Conclusion" ÂåÖÂê´ "introduction" ÁöÑÊÉÖÂÜµÔºâ
            const keywordIndex = normalizedTitle.indexOf(keyword.toLowerCase());
            const beforeKeyword = normalizedTitle.substring(0, keywordIndex);
            const afterKeyword = normalizedTitle.substring(keywordIndex + keyword.length);
            
            // Ê£ÄÊü•ÂÖ≥ÈîÆËØçÂâçÂêéÊòØÂê¶ÊúâÂÖ∂‰ªñ‰∏ªË¶ÅÁ´†ËäÇËØçÔºàÈÅøÂÖçËØØÂåπÈÖçÔºâ
            const conflictingKeywords = ['conclusion', 'discussion', 'methodology', 'method', 'experiment', 'result'];
            const hasConflict = conflictingKeywords.some(conflict => 
              beforeKeyword.includes(conflict) || afterKeyword.includes(conflict)
            );
            
            if (!hasConflict) {
              return true;
            }
          }
        }
        
        return false;
      };
      
      // Find sections that match our patterns - try multiple selectors
      let targetSectionHeads = $('div[type="section"] head').filter((_, el) => {
        const sectionTitle = $(el).text().trim();
        return matchSection(sectionTitle);
      });
      
      // If no target sections found with first selector, try alternatives
      if (targetSectionHeads.length === 0) {
        targetSectionHeads = $('div head').filter((_, el) => {
          const sectionTitle = $(el).text().trim();
          return matchSection(sectionTitle);
        });
      }
      
      if (targetSectionHeads.length === 0) {
        targetSectionHeads = $('head').filter((_, el) => {
          const sectionTitle = $(el).text().trim();
          return matchSection(sectionTitle);
        });
      }
      
      // Â¶ÇÊûúËøòÊòØÊ≤°ÊâæÂà∞ÔºåÂ∞ùËØïÊõ¥ÂÆΩÊùæÁöÑÂåπÈÖçÔºöÊü•ÊâæÂåÖÂê´ÂÖ≥ÈîÆËØçÁöÑÊÆµËêΩÊ†áÈ¢ò
      if (targetSectionHeads.length === 0) {
        console.log('üîç Trying relaxed matching for section titles...');
        const allHeads = $('head').map((_, el) => {
          const title = $(el).text().trim();
          return { element: el, title };
        }).get();
        
        for (const { element, title } of allHeads) {
          if (matchSection(title)) {
            targetSectionHeads = targetSectionHeads.add(element);
          }
        }
      }

      const filteredSections = targetSectionHeads.map((_, el) => $(el).text().trim()).get();
      
      // If no target sections found, fall back to extracting from all content
      if (filteredSections.length === 0) {
        console.log('‚ö†Ô∏è  No target sections found (Introduction/Related Work), falling back to extract all citations');
        console.log('üîç Will analyze first few sections or entire document for citations');
        
        // Try to use first few sections as fallback
        if (allSections.length > 0) {
          console.log(`üìù Available sections in document: ${allSections.slice(0, 10).join(', ')}`);
          console.log(`üí° Tip: If you see sections like "Introduction" or "Related Work" above, they may have different naming in this paper`);
        } else {
          console.log(`‚ö†Ô∏è  No sections detected in document structure`);
        }
      } else {
        console.log(`‚úÖ Target sections found (${filteredSections.length}): ${filteredSections.join(', ')}`);
      }

      // Extract bibliography entries first
      const bibliographyMap = new Map<string, any>();
      $('listBibl biblStruct').each((_, biblStruct) => {
        const $bibl = $(biblStruct);
        const xmlId = $bibl.attr('xml:id');
        
        if (xmlId) {
          const title = $bibl.find('title[level="a"]').first().text().trim() ||
                       $bibl.find('title').first().text().trim();
          
          // Extract all authors from bibliography entry
          // GROBID structure: <author><persName><forename>...</forename><surname>...</surname></persName></author>
          const authors = $bibl.find('author').map((_, authorEl) => {
            const $author = $(authorEl);
            const persName = $author.find('persName').first();
            if (persName.length > 0) {
              // Handle multiple forenames
              const allForenames = persName.find('forename').map((_, fn) => $(fn).text().trim()).get().join(' ');
              const surname = persName.find('surname').text().trim();
              return `${allForenames} ${surname}`.trim();
            }
            // Fallback to direct text
            return $author.text().trim();
          }).get().filter(name => name.length > 0);

          const year = $bibl.find('date').attr('when') || 
                      $bibl.find('date').text().trim();

          bibliographyMap.set(xmlId, {
            id: xmlId,
            title,
            authors,
            year
          });
        }
      });

      console.log(`Found ${bibliographyMap.size} bibliography entries`);

      // Extract citations from target sections or all content as fallback
      const citations: Array<{
        id: string;
        title?: string;
        authors?: string[];
        year?: string;
        context: string;
        contextBefore: string;
        contextAfter: string;
        section?: string;
      }> = [];

      if (filteredSections.length > 0) {
        // Process each target section
        targetSectionHeads.each((_, head) => {
          const $head = $(head);
          const sectionTitle = $head.text().trim();
          const $section = $head.parent();

          console.log(`Processing section: ${sectionTitle}`);
          
          // Debug: Log section content structure
          console.log(`üîç Section content preview: ${$section.text().substring(0, 200)}...`);
          
          // Debug: Count citation references in this section
          const citationRefs = $section.find('ref[type="bibr"]');
          console.log(`üìä Found ${citationRefs.length} citation references in section "${sectionTitle}"`);
          
          // Also try alternative selectors
          const altRefs1 = $section.find('ref');
          const altRefs2 = $section.find('[target^="#"]');
          console.log(`üìä Alternative counts: ref=${altRefs1.length}, target=#=${altRefs2.length}`);

          // Find all citation references in this section - ÊîπËøõÂåπÈÖçÈÄªËæë
          // Â∞ùËØïÂ§öÁßçÈÄâÊã©Âô®‰ª•ÊçïËé∑ÊâÄÊúâÂºïÁî®
          const citationSelectors = [
            'ref[type="bibr"]',
            'ref[target^="#"]',
            'ref'
          ];
          
          let foundRefs = $section.find(citationSelectors[0]);
          if (foundRefs.length === 0) {
            foundRefs = $section.find(citationSelectors[1]);
          }
          if (foundRefs.length === 0) {
            foundRefs = $section.find(citationSelectors[2]);
          }
          
          foundRefs.each((_, ref) => {
            const $ref = $(ref);
            const target = $ref.attr('target');
            
            if (target && target.startsWith('#')) {
              const bibId = target.substring(1);
              let bibInfo = bibliographyMap.get(bibId);
              
              // Â¶ÇÊûúÁõ¥Êé•ÂåπÈÖçÂ§±Ë¥•ÔºåÂ∞ùËØïÊ®°Á≥äÂåπÈÖç
              if (!bibInfo) {
                // Â∞ùËØïÂåπÈÖçÈÉ®ÂàÜ IDÔºàÊúâ‰∫õ GROBID ËæìÂá∫ÂèØËÉΩ ID ‰∏çÂÆåÊï¥Ôºâ
                for (const [id, info] of bibliographyMap.entries()) {
                  if (id.includes(bibId) || bibId.includes(id)) {
                    bibInfo = info;
                    console.log(`‚ö†Ô∏è  Using fuzzy match: ${bibId} -> ${id}`);
                    break;
                  }
                }
              }
              
              if (bibInfo) {
                // Get surrounding context with improved sentence boundary detection
                const fullText = $section.text();
                const refText = $ref.text();
                const refIndex = fullText.indexOf(refText);
                
                if (refIndex !== -1) {
                  console.log(`üîç Extracting context for citation "${refText}" at position ${refIndex}`);
                  
                  // Get a larger initial context window
                  const contextRadius = 300; // Increased from 100 to 300
                  const beforeStart = Math.max(0, refIndex - contextRadius);
                  const afterEnd = Math.min(fullText.length, refIndex + refText.length + contextRadius);
                  
                  let contextBefore = fullText.substring(beforeStart, refIndex);
                  let contextAfter = fullText.substring(refIndex + refText.length, afterEnd);
                  
                  // Try to find complete sentences by looking for sentence boundaries
                  // Improve contextBefore to start at sentence beginning
                  const sentenceStartPattern = /[.!?]\s+[A-Z]/g;
                  let match;
                  let lastSentenceStart = 0;
                  while ((match = sentenceStartPattern.exec(contextBefore)) !== null) {
                    lastSentenceStart = match.index + match[0].indexOf(match[0].match(/[A-Z]/)![0]);
                  }
                  if (lastSentenceStart > 0) {
                    contextBefore = contextBefore.substring(lastSentenceStart);
                  }
                  
                  // Improve contextAfter to end at sentence boundary
                  const sentenceEndMatch = contextAfter.match(/[.!?]\s/);
                  if (sentenceEndMatch) {
                    const endPos = sentenceEndMatch.index! + 1;
                    contextAfter = contextAfter.substring(0, endPos);
                  }
                  
                  const context = (contextBefore + refText + contextAfter).trim();
                  
                  // console.log(`üìù Context extracted (${context.length} chars):`);
                  // console.log(`   Before: "${contextBefore.substring(0, 50)}..."`);
                  // console.log(`   Citation: "${refText}"`);
                  // console.log(`   After: "${contextAfter.substring(0, 50)}..."`);
                  // console.log(`   Full context: "${context}"`);

                  citations.push({
                    ...bibInfo,
                    context: context,
                    contextBefore: contextBefore.trim(),
                    contextAfter: contextAfter.trim(),
                    section: sectionTitle
                  });
                } else {
                  console.log(`‚ö†Ô∏è Could not find citation text "${refText}" in section content`);
                }
              } else {
                console.log(`‚ö†Ô∏è No bibliography info found for target: ${target}`);
              }
            } else {
              console.log(`‚ö†Ô∏è Invalid or missing target attribute: ${target}`);
            }
          });
        });
        
        console.log(`üìã Extracted ${citations.length} citations from target sections`);
        
        // If no citations found in target sections, try fallback approach
        if (citations.length === 0) {
          console.log('‚ö†Ô∏è  No citations found in target sections, trying fallback...');
          
          // Fallback: extract citations from entire document
          console.log('Extracting citations from entire document...');
          
          // First, count total bibliography entries and citation references
          const totalBibEntries = $('listBibl biblStruct').length;
          const totalCitationRefs = $('ref[type="bibr"]').length;
          // console.log(`üìä Document statistics:`);
          // console.log(`   - Bibliography entries: ${totalBibEntries}`);
          // console.log(`   - Citation references: ${totalCitationRefs}`);
          
          $('ref[type="bibr"]').each((_, ref) => {
            const $ref = $(ref);
            const target = $ref.attr('target');
            
            if (target && target.startsWith('#')) {
              const bibId = target.substring(1);
              const bibInfo = bibliographyMap.get(bibId);
              
              if (bibInfo) {
                console.log(`üîç Fallback: Processing citation "${$ref.text()}" with target ${target}`);
                
                // Get surrounding context from the parent paragraph/section
                const $parent = $ref.closest('p, div');
                let context = $parent.text().trim();
                
                // If context is too long, try to get a more focused excerpt
                const refText = $ref.text();
                const refIndex = context.indexOf(refText);
                
                if (refIndex !== -1 && context.length > 500) {
                  // Extract context with improved sentence boundaries
                  const contextRadius = 300;
                  const beforeStart = Math.max(0, refIndex - contextRadius);
                  const afterEnd = Math.min(context.length, refIndex + refText.length + contextRadius);
                  
                  let contextBefore = context.substring(beforeStart, refIndex);
                  let contextAfter = context.substring(refIndex + refText.length, afterEnd);
                  
                  // Try to find complete sentences
                  const sentenceStartPattern = /[.!?]\s+[A-Z]/g;
                  let match;
                  let lastSentenceStart = 0;
                  while ((match = sentenceStartPattern.exec(contextBefore)) !== null) {
                    lastSentenceStart = match.index + match[0].indexOf(match[0].match(/[A-Z]/)![0]);
                  }
                  if (lastSentenceStart > 0) {
                    contextBefore = contextBefore.substring(lastSentenceStart);
                  }
                  
                  const sentenceEndMatch = contextAfter.match(/[.!?]\s/);
                  if (sentenceEndMatch) {
                    const endPos = sentenceEndMatch.index! + 1;
                    contextAfter = contextAfter.substring(0, endPos);
                  }
                  
                  context = (contextBefore + refText + contextAfter).trim();
                }
                
                // console.log(`üìù Fallback context extracted (${context.length} chars): "${context}"`);

                citations.push({
                  ...bibInfo,
                  context: context,
                  contextBefore: '',
                  contextAfter: '',
                  section: 'Unknown'
                });
              }
            }
          });
          
          console.log(`üìã Extracted ${citations.length} citations via fallback method`);
        }
      } else {
        // Fallback: extract citations from entire document
        console.log('Extracting citations from entire document...');
        
        // First, count total bibliography entries and citation references
        const totalBibEntries = $('listBibl biblStruct').length;
        const totalCitationRefs = $('ref[type="bibr"]').length;
        // console.log(`üìä Document statistics:`);
        // console.log(`   - Bibliography entries: ${totalBibEntries}`);
        // console.log(`   - Citation references: ${totalCitationRefs}`);
        
        $('ref[type="bibr"]').each((_, ref) => {
          const $ref = $(ref);
          const target = $ref.attr('target');
          
          if (target && target.startsWith('#')) {
            const bibId = target.substring(1);
            let bibInfo = bibliographyMap.get(bibId);
            
            // Â¶ÇÊûúÁõ¥Êé•ÂåπÈÖçÂ§±Ë¥•ÔºåÂ∞ùËØïÊ®°Á≥äÂåπÈÖç
            if (!bibInfo) {
              for (const [id, info] of bibliographyMap.entries()) {
                if (id.includes(bibId) || bibId.includes(id)) {
                  bibInfo = info;
                  console.log(`‚ö†Ô∏è  Fallback: Using fuzzy match: ${bibId} -> ${id}`);
                  break;
                }
              }
            }
            
            if (bibInfo) {
              // Get surrounding context from the entire document
              const $parent = $ref.closest('p, div');
              let context = $parent.text().trim();
              
              // ÊîπËøõ context ÊèêÂèñÔºöÂ∞ùËØïËé∑ÂèñÊõ¥ÂÆåÊï¥ÁöÑÂè•Â≠ê
              if (context.length > 500) {
                const refText = $ref.text();
                const refIndex = context.indexOf(refText);
                if (refIndex !== -1) {
                  const contextRadius = 200;
                  const beforeStart = Math.max(0, refIndex - contextRadius);
                  const afterEnd = Math.min(context.length, refIndex + refText.length + contextRadius);
                  context = context.substring(beforeStart, afterEnd);
                }
              }
              
              citations.push({
                ...bibInfo,
                context: context.substring(0, 500), // Â¢ûÂä† context ÈïøÂ∫¶ÈôêÂà∂
                contextBefore: '',
                contextAfter: '',
                section: 'Unknown'
              });
            } else {
              console.log(`‚ö†Ô∏è  No bibliography info found for citation target: ${target}`);
            }
          }
        });
        
        console.log(`üìã Extracted ${citations.length} citations via fallback method`);
      }

      // Remove duplicates based on title, authors, and year (not just ID)
      const uniqueCitations = this.removeDuplicateCitationsByContent(citations);    

      return {
        success: true,
        paperTitle,
        paperAuthors,
        paperAbstract,
        paperVenue,
        paperYear,
        paperCitationCount, // Êñ∞Â¢ûÔºöÂºïÁî®Ê¨°Êï∏
        teiXml, // Êñ∞Â¢ûÔºöËøîÂõû TEI XML
        citations: uniqueCitations,
        totalSections: allSections,
        filteredSections,
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      console.error('Citation extraction failed:', errorMessage);
      return {
        success: false,
        citations: [],
        error: errorMessage
      };
    }
  }
}
