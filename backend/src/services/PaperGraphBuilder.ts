/**
 * Paper Graph Builder Service
 * æ•´åˆ GROBID å’Œ LLM åˆ†æï¼Œæ§‹å»ºè«–æ–‡é—œä¿‚åœ–
 */

import { AdvancedCitationService } from './AdvancedCitationService';
import { PaperRelationshipAnalyzer, PaperMetadata, PaperGraph } from './PaperRelationshipAnalyzer';
import { SemanticScholarService } from './SemanticScholarService';

export interface PaperInput {
  url: string;
  title?: string; // å¯é¸ï¼Œç”¨æ–¼è¦†è“‹è‡ªå‹•æå–çš„æ¨™é¡Œ
}

export interface GraphBuildResult {
  success: boolean;
  graph?: PaperGraph;
  papers?: PaperMetadata[];
  error?: string;
  stats?: {
    totalPapers: number;
    totalEdges: number;
    processingTime: number;
  };
}

export class PaperGraphBuilder {
  private grobidService: AdvancedCitationService;
  private relationshipAnalyzer: PaperRelationshipAnalyzer;

  constructor() {
    this.grobidService = new AdvancedCitationService();
    this.relationshipAnalyzer = new PaperRelationshipAnalyzer();
  }

  /**
   * å¾å¤šå€‹è«–æ–‡ URL æ§‹å»ºé—œä¿‚åœ–
   */
  async buildGraphFromUrls(paperUrls: string[], progressCallback?: (update: { progress: number; step: string; currentStep: string; details?: string }) => void): Promise<GraphBuildResult> {
    const startTime = Date.now();
    
    try {
      console.log(`\n=== Building Paper Graph from ${paperUrls.length} URLs ===`);

      // 1. æª¢æŸ¥æœå‹™å¯ç”¨æ€§
      progressCallback?.({
        progress: 10,
        step: 'initializing',
        currentStep: 'Checking services...',
        details: 'Verifying GROBID and LLM availability'
      });
      
      const servicesReady = await this.checkServicesPrivate();
      if (!servicesReady.grobid || !servicesReady.llm) {
        return {
          success: false,
          error: `Services not ready - GROBID: ${servicesReady.grobid}, LLM: ${servicesReady.llm}`
        };
      }

      // 2. ä½¿ç”¨ GROBID æå–æ¯ç¯‡è«–æ–‡çš„æ•¸æ“š
      console.log('\n--- Step 1: Extracting Paper Data with GROBID ---');
      const papers: PaperMetadata[] = [];
      const extractionStartProgress = 15;
      const extractionEndProgress = 50;
      const progressPerPaper = (extractionEndProgress - extractionStartProgress) / paperUrls.length;
      
      for (let i = 0; i < paperUrls.length; i++) {
        const url = paperUrls[i];
        const currentProgress = extractionStartProgress + (i * progressPerPaper);
        
        progressCallback?.({
          progress: currentProgress,
          step: 'extracting',
          currentStep: `Processing paper ${i + 1}/${paperUrls.length}`,
          details: `Extracting metadata from ${url}`
        });
        
        console.log(`Processing paper ${i + 1}/${paperUrls.length}: ${url}`);
        
        const paperData = await this.extractPaperData(url);
        if (paperData) {
          papers.push(paperData);
          console.log(`âœ… Extracted: ${paperData.title}`);
          progressCallback?.({
            progress: currentProgress + (progressPerPaper * 0.8),
            step: 'extracting',
            currentStep: `Extracted: ${paperData.title.substring(0, 50)}...`,
            details: `Successfully processed paper ${i + 1}/${paperUrls.length}`
          });
        } else {
          console.log(`âŒ Failed to extract data from: ${url}`);
        }
      }

      if (papers.length === 0) {
        return {
          success: false,
          error: 'No papers could be processed successfully'
        };
      }

      // 3. ä½¿ç”¨ LLM åˆ†æè«–æ–‡é—œä¿‚
      progressCallback?.({
        progress: 55,
        step: 'analyzing',
        currentStep: 'Analyzing relationships...',
        details: 'Using LLM to identify paper relationships'
      });
      
      console.log('\n--- Step 2: Analyzing Relationships with LLM ---');
      
      // å°‡å¼•ç”¨è½‰æ›ç‚ºé¡å¤–çš„è«–æ–‡ç¯€é»ï¼ˆæ·±åº¦1è¡¨ç¤ºåªæå–ä¸€å±¤å¼•ç”¨ï¼‰
      progressCallback?.({
        progress: 60,
        step: 'analyzing',
        currentStep: 'Expanding citation network...',
        details: 'Extracting cited papers'
      });
      
      const allPapers = await this.expandPapersWithCitations(papers, 1, progressCallback);
      console.log(`Expanded to ${allPapers.length} total papers (including ${allPapers.length - papers.length} cited papers)`);
      
      progressCallback?.({
        progress: 70,
        step: 'analyzing',
        currentStep: 'Analyzing paper pairs...',
        details: `Analyzing relationships between ${allPapers.length} papers`
      });
      
      let graph = await this.relationshipAnalyzer.buildRelationshipGraph(allPapers);
      
      progressCallback?.({
        progress: 85,
        step: 'building',
        currentStep: 'Building graph structure...',
        details: `Created ${graph.nodes.length} nodes and ${graph.edges.length} relationships`
      });

      // 3.5 ç²å–ä¸¦æ·»åŠ  Derivative Works
      console.log('\n--- Step 3: Fetching Derivative Works ---');
      progressCallback?.({
        progress: 90,
        step: 'building',
        currentStep: 'Fetching derivative works...',
        details: 'Querying Semantic Scholar for citing papers'
      });
      
      graph = await this.appendDerivativeWorks(graph, papers);
      
      progressCallback?.({
        progress: 95,
        step: 'building',
        currentStep: 'Finalizing graph...',
        details: `Final graph: ${graph.nodes.length} nodes and ${graph.edges.length} relationships`
      });

      const processingTime = Date.now() - startTime;

      return {
        success: true,
        graph,
        papers,
        stats: {
          totalPapers: papers.length,
          totalEdges: graph.edges.length,
          processingTime
        }
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      console.error('Graph building failed:', errorMessage);
      
      return {
        success: false,
        error: errorMessage
      };
    }
  }

  /**
   * å¾è«–æ–‡ URL æå–æ•¸æ“šï¼ˆåŒ…å«å¼•ç”¨ä¿¡æ¯ï¼‰
   */
  private async extractPaperData(url: string): Promise<PaperMetadata | null> {
    try {
      // ä½¿ç”¨éæ¿¾ç‰ˆæœ¬çš„ GROBID æå–å¼•ç”¨ï¼ˆåƒ… Related Work å’Œ Introductionï¼‰
      const citationResult = await this.grobidService.extractCitationsWithContextFiltered(url);
      
      if (!citationResult.success) {
        console.error(`Failed to extract citations from ${url}:`, citationResult.error);
        return null;
      }

      // ç”Ÿæˆå”¯ä¸€ IDï¼ˆåŸºæ–¼ URLï¼‰
      const id = this.generatePaperId(url);

      // å˜—è©¦å¾ arXiv ç²å–æ›´å¥½çš„ abstract
      let finalAbstract = citationResult.paperAbstract;
      const title = citationResult.paperTitle || 'Unknown Title';
      
      if (title !== 'Unknown Title') {
        console.log(`ğŸ” Attempting to find arXiv version for better abstract: ${title.slice(0, 50)}...`);
        const arxivUrl = await this.inferArxivUrl(title);
        
        if (arxivUrl) {
          console.log(`ğŸ“„ Found arXiv version: ${arxivUrl}`);
          try {
            const PaperService = require('./PaperService').PaperService;
            const paperService = new PaperService();
            const arxivData = await paperService.fetchPaperByUrl(arxivUrl);
            
            if (arxivData && arxivData.abstract && arxivData.abstract.trim()) {
              console.log(`âœ… Using arXiv abstract (${arxivData.abstract.length} chars) instead of GROBID abstract (${finalAbstract?.length || 0} chars)`);
              finalAbstract = arxivData.abstract;
            }
          } catch (error) {
            console.log(`âš ï¸ Failed to fetch arXiv abstract: ${error instanceof Error ? error.message : 'Unknown error'}`);
          }
        }
      }

      // æå– arXiv ID
      const arxivIdMatch = url.match(/arxiv\.org\/(?:abs|pdf)\/([^\/\?]+)/i);
      const arxivId = arxivIdMatch ? arxivIdMatch[1].replace(/\.pdf$/, '') : undefined;

      // æ§‹å»º PaperMetadata
      const paperMetadata = {
        id,
        title,
        authors: citationResult.paperAuthors || [],
        year: citationResult.paperYear || this.extractYearFromUrl(url) || 'Unknown',
        abstract: finalAbstract,
        venue: citationResult.paperVenue,
        url: url, // ä¿å­˜åŸå§‹ URL
        arxivId: arxivId, // ä¿å­˜ arXiv ID
        citationCount: citationResult.paperCitationCount, // æ–°å¢ï¼šå¼•ç”¨æ¬¡æ•¸
        paperCitationCount: citationResult.paperCitationCount, // ç›´æ¥ä½¿ç”¨ paperCitationCount
        citations: citationResult.citations
      };
      
      console.log(`ğŸ” [PAPER GRAPH DEBUG] Created PaperMetadata with:`, {
        id,
        title: title?.substring(0, 50) + '...',
        url: url,
        arxivId: arxivId,
        citationCount: citationResult.paperCitationCount,
        paperCitationCount: citationResult.paperCitationCount
      });
      
      return paperMetadata;

    } catch (error) {
      console.error(`Error extracting paper data from ${url}:`, error);
      return null;
    }
  }

  /**
   * ä½¿ç”¨ç¯©é¸å¾Œçš„å¼•ç”¨æå–æ§‹å»ºé—œä¿‚åœ–ï¼ˆåªå¾ Introduction/Related Work éƒ¨åˆ†ï¼‰
   */
  async buildGraphWithFilteredCitations(paperUrls: string[], expansionDepth: number = 0, progressCallback?: (update: { progress: number; step: string; currentStep: string; details?: string }) => void): Promise<GraphBuildResult> {
    const startTime = Date.now();
    
    try {
      console.log(`\n=== Building Paper Graph with Filtered Citations from ${paperUrls.length} URLs (depth: ${expansionDepth}) ===`);

      // 1. æª¢æŸ¥æœå‹™å¯ç”¨æ€§
      progressCallback?.({
        progress: 10,
        step: 'initializing',
        currentStep: 'Checking services...',
        details: 'Verifying GROBID and LLM availability'
      });
      
      const servicesReady = await this.checkServicesPrivate();
      if (!servicesReady.grobid || !servicesReady.llm) {
        return {
          success: false,
          error: `Services not ready - GROBID: ${servicesReady.grobid}, LLM: ${servicesReady.llm}`
        };
      }

      // 2. æå–è«–æ–‡æ•¸æ“šï¼ˆä½¿ç”¨ç¯©é¸å¾Œçš„å¼•ç”¨ï¼‰
      console.log('\nğŸ“‹ Extracting paper data with filtered citations...');
      const papers: PaperMetadata[] = [];
      const extractionStartProgress = 15;
      const extractionEndProgress = 50;
      const progressPerPaper = (extractionEndProgress - extractionStartProgress) / paperUrls.length;
      
      for (let i = 0; i < paperUrls.length; i++) {
        const url = paperUrls[i];
        const currentProgress = extractionStartProgress + (i * progressPerPaper);
        
        progressCallback?.({
          progress: currentProgress,
          step: 'extracting',
          currentStep: `Processing paper ${i + 1}/${paperUrls.length} (filtered)`,
          details: `Extracting citations from key sections: ${url}`
        });
        
        const paperData = await this.extractPaperDataFiltered(url);
        if (paperData) {
          papers.push(paperData);
          progressCallback?.({
            progress: currentProgress + (progressPerPaper * 0.8),
            step: 'extracting',
            currentStep: `Extracted: ${paperData.title.substring(0, 50)}...`,
            details: `Successfully processed paper ${i + 1}/${paperUrls.length}`
          });
        }
      }

      if (papers.length === 0) {
        return {
          success: false,
          error: 'No papers could be extracted'
        };
      }

      console.log(`âœ… Successfully extracted ${papers.length} papers with filtered citations`);

      // 2.5. æ·±åº¦å¼•ç”¨æ“´å±•ï¼ˆç¶²ç‹€ç™¼æ•£åˆ†æï¼‰- é™åˆ¶æ•°é‡é¿å…èŠ‚ç‚¹è¿‡å¤š
      let allPapers = papers;
      if (expansionDepth > 0) {
        console.log(`\nğŸ•¸ï¸  Starting network expansion analysis (depth: ${expansionDepth}, limited to top 30 prior works)`);
        progressCallback?.({
          progress: 50,
          step: 'extracting',
          currentStep: 'Starting citation network expansion...',
          details: `Expanding network to depth ${expansionDepth} (limited to top 30 prior works)`
        });
        // é™åˆ¶æ‰©å±•ï¼šæœ€å¤šåªå–æ¯ä¸ªè¾“å…¥è®ºæ–‡çš„å‰ 30 ä¸ªå¼•ç”¨
        const limitedPapers = papers.map(p => ({ ...p, maxCitations: 30 }));
        allPapers = await this.expandPapersWithCitations(limitedPapers, expansionDepth, progressCallback);
        console.log(`ğŸ“ˆ Expanded from ${papers.length} to ${allPapers.length} papers through citation network (limited)`);
      } else {
        // å³ä½¿ expansionDepth=0ï¼Œä¹Ÿè¦é™åˆ¶å¼•ç”¨çš„æ•°é‡ï¼ˆåªå–å‰ 20 ä¸ªï¼‰
        console.log(`\nğŸ“š Limiting citations to top 20 per paper to avoid too many nodes`);
        for (const paper of allPapers) {
          if (paper.citations && paper.citations.length > 20) {
            paper.citations = paper.citations.slice(0, 20);
            console.log(`   Limited citations for "${paper.title.substring(0, 50)}..." to 20`);
          }
        }
      }

      // 3. åˆ†æè«–æ–‡é—œä¿‚
      progressCallback?.({
        progress: 55,
        step: 'analyzing',
        currentStep: 'Analyzing relationships...',
        details: 'Using LLM to identify paper relationships'
      });
      
      console.log('\nğŸ” Analyzing paper relationships...');
      
      progressCallback?.({
        progress: 70,
        step: 'analyzing',
        currentStep: 'Analyzing paper pairs...',
        details: `Analyzing relationships between ${allPapers.length} papers`
      });
      
      let graph = await this.relationshipAnalyzer.buildRelationshipGraph(allPapers);
      
      progressCallback?.({
        progress: 85,
        step: 'building',
        currentStep: 'Building graph structure...',
        details: `Created ${graph.nodes.length} nodes and ${graph.edges.length} relationships`
      });
      
      // 3.5 è¡¥å…… Derivative Worksï¼ˆå¼•ç”¨è¿™äº›è®ºæ–‡çš„åç»­è®ºæ–‡ï¼‰
      console.log('\n--- Step 3.5: Fetching Derivative Works (filtered) ---');
      // NOTE: ä¸å†å°† derivative works æ·»åŠ åˆ° graph ä¸­ï¼Œé¿å…å¤ªå¤š nodes
      // Derivative works åº”è¯¥åªåœ¨åˆ—è¡¨ä¸­æ˜¾ç¤ºï¼ˆé€šè¿‡ PaperCitationService è·å–ï¼‰
      // graph = await this.appendDerivativeWorks(graph, papers);
      
      const processingTime = Date.now() - startTime;
      
      console.log(`âœ… Graph construction completed in ${processingTime}ms`);
      console.log(`ğŸ“Š Final graph: ${graph.nodes.length} nodes, ${graph.edges.length} edges`);

      return {
        success: true,
        graph,
        papers: allPapers, // ä¿®æ­£ï¼šè¿”å›æ“´å±•å¾Œçš„æ‰€æœ‰è«–æ–‡
        stats: {
          totalPapers: allPapers.length, // ä¿®æ­£ï¼šä½¿ç”¨æ“´å±•å¾Œçš„è«–æ–‡æ•¸é‡
          totalEdges: graph.edges.length,
          processingTime
        }
      };
      
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      console.error('Graph building error:', errorMessage);
      return {
        success: false,
        error: errorMessage
      };
    }
  }

  /**
   * å¾è«–æ–‡ URL æå–æ•¸æ“šï¼ˆä½¿ç”¨ç¯©é¸å¾Œçš„å¼•ç”¨æå–ï¼‰
   */
  private async extractPaperDataFiltered(url: string): Promise<PaperMetadata | null> {
    try {
      // ä½¿ç”¨ç¯©é¸ç‰ˆæœ¬çš„ GROBID æå–å¼•ç”¨ï¼ˆåƒ… Related Work å’Œ Introductionï¼‰
      const citationResult = await this.grobidService.extractCitationsWithContextFiltered(url);
      
      if (!citationResult.success) {
        console.error(`Failed to extract filtered citations from ${url}:`, citationResult.error);
        return null;
      }

      console.log(`ğŸ“Š Filtered section analysis for ${url}:`);
      console.log(`   - Total sections found: ${citationResult.totalSections || 0}`);
      console.log(`   - Filtered sections: ${citationResult.filteredSections?.join(', ') || 'none'}`);
      console.log(`   - Citations from filtered sections: ${citationResult.citations.length}`);

      // ç”Ÿæˆå”¯ä¸€ IDï¼ˆåŸºæ–¼ URLï¼‰
      const id = this.generatePaperId(url);

      // å˜—è©¦å¾ arXiv ç²å–æ›´å¥½çš„ abstract
      let finalAbstract = citationResult.paperAbstract;
      const title = citationResult.paperTitle || 'Unknown Title';
      
      if (title !== 'Unknown Title') {
        console.log(`ğŸ” Attempting to find arXiv version for better abstract: ${title.slice(0, 50)}...`);
        const arxivUrl = await this.inferArxivUrl(title);
        
        if (arxivUrl) {
          console.log(`ğŸ“„ Found arXiv version: ${arxivUrl}`);
          try {
            const PaperService = require('./PaperService').PaperService;
            const paperService = new PaperService();
            const arxivData = await paperService.fetchPaperByUrl(arxivUrl);
            
            if (arxivData && arxivData.abstract && arxivData.abstract.trim()) {
              console.log(`âœ… Using arXiv abstract (${arxivData.abstract.length} chars) instead of GROBID abstract (${finalAbstract?.length || 0} chars)`);
              finalAbstract = arxivData.abstract;
            }
          } catch (error) {
            console.log(`âš ï¸ Failed to fetch arXiv abstract: ${error instanceof Error ? error.message : 'Unknown error'}`);
          }
        }
      }

      // æå– arXiv ID
      const arxivIdMatch = url.match(/arxiv\.org\/(?:abs|pdf)\/([^\/\?]+)/i);
      const arxivId = arxivIdMatch ? arxivIdMatch[1].replace(/\.pdf$/, '') : undefined;

      // æ§‹å»º PaperMetadata
      const paperMetadata = {
        id,
        title,
        authors: citationResult.paperAuthors || [],
        year: citationResult.paperYear || this.extractYearFromUrl(url) || 'Unknown',
        abstract: finalAbstract,
        venue: citationResult.paperVenue,
        url: url, // ä¿å­˜åŸå§‹ URL
        arxivId: arxivId, // ä¿å­˜ arXiv ID
        citationCount: citationResult.paperCitationCount, // æ–°å¢ï¼šå¼•ç”¨æ¬¡æ•¸
        paperCitationCount: citationResult.paperCitationCount, // ç›´æ¥ä½¿ç”¨ paperCitationCount
        citations: citationResult.citations
      };
      
      console.log(`ğŸ” [PAPER GRAPH FILTERED DEBUG] Created PaperMetadata with:`, {
        id,
        title: title?.substring(0, 50) + '...',
        url: url,
        arxivId: arxivId,
        citationCount: citationResult.paperCitationCount,
        paperCitationCount: citationResult.paperCitationCount
      });
      
      return paperMetadata;

    } catch (error) {
      console.error(`Error extracting filtered paper data from ${url}:`, error);
      return null;
    }
  }

  /**
   * æª¢æŸ¥æ‰€éœ€æœå‹™æ˜¯å¦å¯ç”¨
   */
  private async checkServices(): Promise<{ grobid: boolean; llm: boolean }> {
    const [grobidReady, llmReady] = await Promise.all([
      this.grobidService.testGrobidConnection(),
      this.relationshipAnalyzer.testLLMConnection()
    ]);

    console.log(`Service Status - GROBID: ${grobidReady ? 'âœ…' : 'âŒ'}, LLM: ${llmReady ? 'âœ…' : 'âŒ'}`);

    return {
      grobid: grobidReady,
      llm: llmReady
    };
  }

  /**
   * å°‡å¼•ç”¨è½‰æ›ç‚ºé¡å¤–çš„è«–æ–‡ç¯€é»ï¼Œæ“´å±•è«–æ–‡åˆ—è¡¨ï¼ˆæ”¯æŒæ·±åº¦æå–ï¼‰
   * æ”¹é€²ç‰ˆï¼šç¢ºä¿å¼•ç”¨è«–æ–‡ä¹Ÿé€šéGROBIDè™•ç†ï¼Œé¿å…é‡è¤‡ï¼Œå»ºç«‹å®Œæ•´çš„å¼•ç”¨ç¶²çµ¡
   */
  private async expandPapersWithCitations(
    mainPapers: PaperMetadata[], 
    depth: number = 1,
    progressCallback?: (update: { progress: number; step: string; currentStep: string; details?: string }) => void
  ): Promise<PaperMetadata[]> {
    const allPapers: PaperMetadata[] = [...mainPapers];
    const processedPaperIds = new Set<string>();
    const processedUrls = new Set<string>();

    // è¨˜éŒ„å·²æœ‰çš„è«–æ–‡IDå’ŒURL
    for (const paper of mainPapers) {
      processedPaperIds.add(paper.id);
      // å¦‚æœè«–æ–‡æœ‰åŸå§‹URLï¼Œä¹Ÿè¨˜éŒ„ä¸‹ä¾†
      const url = await this.inferArxivUrl(paper.title);
      if (url) processedUrls.add(url);
    }

    console.log(`\nğŸ”— Expanding papers with citations (depth: ${depth})`);

    // ä½¿ç”¨éšŠåˆ—ä¾†è™•ç†å±¤ç´šéæ­¸
    const papersToProcess = [...mainPapers];
    let currentDepth = 0;
    let processedCitations = 0;
    let totalProcessed = 0;

    progressCallback?.({
      progress: 50,
      step: 'extracting',
      currentStep: 'Expanding citation network...',
      details: `Starting network expansion to depth ${depth} (this may take a while for large networks)`
    });

    while (currentDepth < depth && papersToProcess.length > 0) {
      currentDepth++;
      const currentLevelPapers = [...papersToProcess];
      papersToProcess.length = 0; // æ¸…ç©ºå¾…è™•ç†éšŠåˆ—

      console.log(`\nğŸ“ˆ Processing depth ${currentDepth}, analyzing ${currentLevelPapers.length} papers`);

      progressCallback?.({
        progress: 50 + (currentDepth - 1) * (30 / depth),
        step: 'extracting',
        currentStep: `Processing depth ${currentDepth}/${depth}...`,
        details: `Analyzing ${currentLevelPapers.length} papers at depth ${currentDepth}`
      });

      for (let paperIndex = 0; paperIndex < currentLevelPapers.length; paperIndex++) {
        const paper = currentLevelPapers[paperIndex];
        
        if (paper.citations && paper.citations.length > 0) {
          console.log(`Processing ${paper.citations.length} citations from: ${paper.title}`);
          
          progressCallback?.({
            progress: 50 + (currentDepth - 1) * (30 / depth) + (paperIndex / currentLevelPapers.length) * (30 / depth),
            step: 'extracting',
            currentStep: `Analyzing citations from: ${paper.title.substring(0, 40)}...`,
            details: `Processing paper ${paperIndex + 1}/${currentLevelPapers.length} at depth ${currentDepth} (${paper.citations.length} citations)`
          });
          
          for (let citationIndex = 0; citationIndex < paper.citations.length; citationIndex++) {
            const citation = paper.citations[citationIndex];
            
            // è·³éæ²’æœ‰æ¨™é¡Œçš„å¼•ç”¨
            if (!citation.title) continue;
            
            processedCitations++;
            totalProcessed++;
            
            // æ¯è™•ç†3å€‹å¼•ç”¨æˆ–æ¯ç¯‡è«–æ–‡çš„æœ€å¾Œä¸€å€‹å¼•ç”¨æ™‚æ›´æ–°é€²åº¦
            if (processedCitations % 3 === 0 || citationIndex === paper.citations.length - 1) {
              const depthProgressStart = 50 + ((currentDepth - 1) / depth) * 30;
              const depthProgressEnd = 50 + (currentDepth / depth) * 30;
              const paperProgress = depthProgressStart + 
                ((paperIndex / currentLevelPapers.length) * (depthProgressEnd - depthProgressStart));
              const citationProgress = paperProgress + 
                ((citationIndex + 1) / paper.citations.length) * 
                ((depthProgressEnd - depthProgressStart) / currentLevelPapers.length);
              
              progressCallback?.({
                progress: Math.min(80, citationProgress),
                step: 'extracting',
                currentStep: `Extracting citation: ${citation.title.substring(0, 45)}...`,
                details: `Processing citation ${totalProcessed} at depth ${currentDepth} (paper ${paperIndex + 1}/${currentLevelPapers.length}, citation ${citationIndex + 1}/${paper.citations.length})`
              });
            }

            // ç”Ÿæˆå¼•ç”¨è«–æ–‡çš„å”¯ä¸€ID
            const citationId = this.generateCitationId(citation);
            
            // æª¢æŸ¥æ˜¯å¦å·²ç¶“è™•ç†éé€™å€‹è«–æ–‡
            if (processedPaperIds.has(citationId)) {
              console.log(`â­ï¸  Skipping already processed paper: ${citation.title}`);
              continue;
            }

            // å˜—è©¦æ¨æ–·arXiv URL
            const possibleUrl = await this.inferArxivUrl(citation.title, citation.authors, citation.year);
            
            if (possibleUrl && processedUrls.has(possibleUrl)) {
              console.log(`â­ï¸  Skipping already processed URL: ${possibleUrl}`);
              continue;
            }

            // æ¨™è¨˜ç‚ºå·²è™•ç†
            processedPaperIds.add(citationId);
            if (possibleUrl) processedUrls.add(possibleUrl);

            // å˜—è©¦é€šéGROBIDè™•ç†å¼•ç”¨è«–æ–‡
            let citedPaper: PaperMetadata;
            
            if (possibleUrl) {
              console.log(`ğŸ” Attempting GROBID extraction for: ${citation.title}`);
              console.log(`ğŸ“ Inferred URL: ${possibleUrl}`);
              
              try {
                // ä½¿ç”¨GROBIDæå–å¼•ç”¨è«–æ–‡çš„å®Œæ•´ä¿¡æ¯ï¼ˆåŒ…æ‹¬å…¶å¼•ç”¨ï¼‰
                const extractedPaper = await this.extractPaperDataFiltered(possibleUrl);
                
                if (extractedPaper) {
                  console.log(`âœ… Successfully extracted via GROBID: ${citation.title}`);
                  console.log(`ğŸ“š Found ${extractedPaper.citations.length} citations in this paper`);
                  citedPaper = extractedPaper;
                  
                  // å¦‚æœé‚„æœ‰æ·±åº¦å‰©é¤˜ï¼Œå°‡æ­¤è«–æ–‡æ·»åŠ åˆ°ä¸‹ä¸€è¼ªè™•ç†éšŠåˆ—
                  if (currentDepth < depth && extractedPaper.citations.length > 0) {
                    papersToProcess.push(extractedPaper);
                    console.log(`ğŸ”„ Added to next level processing: ${citation.title}`);
                  }
                } else {
                  console.log(`âš ï¸  GROBID extraction failed, using basic citation info: ${citation.title}`);
                  citedPaper = this.createBasicCitedPaper(citation);
                }
              } catch (error) {
                console.log(`âŒ Error processing ${citation.title}:`, error);
                citedPaper = this.createBasicCitedPaper(citation);
              }
            } else {
              console.log(`ğŸ“„ No URL found, using basic citation info: ${citation.title}`);
              citedPaper = this.createBasicCitedPaper(citation);
            }

            allPapers.push(citedPaper);
          }
        }
      }
    }
    
    progressCallback?.({
      progress: 80,
      step: 'extracting',
      currentStep: 'Citation network expansion complete',
      details: `Expanded from ${mainPapers.length} to ${allPapers.length} papers (${allPapers.length - mainPapers.length} new papers added)`
    });

    console.log(`ğŸ“Š Expanded from ${mainPapers.length} to ${allPapers.length} papers after ${currentDepth} levels`);
    return allPapers;
  }

  /**
   * ç‚ºå¼•ç”¨å‰µå»ºè«–æ–‡å°è±¡ï¼Œå˜—è©¦æå–å¯¦éš›å…§å®¹
   * @deprecated å·²è¢«æ–°çš„ expandPapersWithCitations é‚è¼¯æ›¿ä»£
   */
  /*
  private async createCitedPaperWithContent(citation: any, depth: number): Promise<PaperMetadata> {
    const citationId = this.generateCitationId(citation);
    
    // åŸºæœ¬çš„å¼•ç”¨è«–æ–‡å°è±¡
    let citedPaper: PaperMetadata = {
      id: citationId,
      title: citation.title,
      authors: citation.authors || [],
      year: citation.year || 'Unknown',
      citations: [] // é»˜èªç©ºå¼•ç”¨
    };

    // å¦‚æœæ·±åº¦å¤§æ–¼0ä¸”å¯ä»¥æ¨æ–·URLï¼Œå˜—è©¦æå–å¯¦éš›å…§å®¹
    if (depth > 0 && citation.title) {
      const possibleUrl = await this.inferArxivUrl(citation.title, citation.authors, citation.year);
      
      if (possibleUrl) {
        console.log(`ğŸ” Attempting to extract content for: ${citation.title}`);
        try {
          // å˜—è©¦æå–å¼•ç”¨è«–æ–‡çš„å…§å®¹
          const extractedPaper = await this.extractPaperData(possibleUrl);
          if (extractedPaper) {
            console.log(`âœ… Successfully extracted content for: ${citation.title}`);
            citedPaper = extractedPaper;
            // éæ­¸æå–å¼•ç”¨çš„å¼•ç”¨ï¼ˆæ·±åº¦-1ï¼‰
            if (depth > 1 && extractedPaper.citations.length > 0) {
              console.log(`ğŸ”„ Recursively extracting citations for: ${citation.title}`);
              const expandedCitations = await this.expandPapersWithCitations([extractedPaper], depth - 1);
              // å°‡æ–°ç™¼ç¾çš„è«–æ–‡æ·»åŠ åˆ°å…¨å±€åˆ—è¡¨ï¼ˆé€™éœ€è¦åœ¨èª¿ç”¨æ–¹è™•ç†ï¼‰
            }
          }
        } catch (error) {
          console.log(`âš ï¸  Failed to extract content for: ${citation.title}`);
        }
      }
    }

    return citedPaper;
  }
  */

  /**
   * å˜—è©¦æ ¹æ“šè«–æ–‡ä¿¡æ¯æ¨æ–·arXiv URL
   * æ”¹é€²ç‰ˆï¼šå¯¦éš›æœç´¢arXiv APIä¾†æ‰¾åˆ°è«–æ–‡
   */
  private async inferArxivUrl(title: string, authors?: string[], year?: string): Promise<string | null> {
    try {
      // æ¸…ç†æ¨™é¡Œï¼Œä¿ç•™é€£å­—ç¬¦å’Œå†’è™Ÿï¼Œåªç§»é™¤å¼•è™Ÿå’Œå…¶ä»–å•é¡Œå­—ç¬¦
      const cleanTitle = title.replace(/["\[\]{}]/g, ' ').replace(/\s+/g, ' ').trim();
      
      // å˜—è©¦å¤šç¨®æœå°‹ç­–ç•¥
      const searchStrategies = [
        // ç­–ç•¥1: ç²¾ç¢ºæ¨™é¡Œæœå°‹
        `ti:"${cleanTitle}"`,
        // ç­–ç•¥2: æ¨™é¡Œ + ä½œè€…
        authors && authors.length > 0 ? 
          `ti:"${cleanTitle}" AND au:"${authors[0].replace(/["\[\]{}]/g, ' ').replace(/\s+/g, ' ').trim()}"` : 
          null,
        // ç­–ç•¥3: ä¸å€åˆ†å¤§å°å¯«çš„æ¨™é¡Œæœå°‹ï¼ˆä½¿ç”¨allå­—æ®µï¼‰
        `all:"${cleanTitle}"`,
        // ç­–ç•¥4: æ‹†åˆ†é—œéµè©æœå°‹
        cleanTitle.split(/[:\-\s]+/)
          .filter(word => word.length > 2)
          .slice(0, 5)
          .map(word => `ti:"${word}"`)
          .join(' AND ')
      ].filter(Boolean);
      
      console.log(`ğŸ” Searching arXiv for: ${title}`);
      
      // å˜—è©¦æ¯ç¨®æœå°‹ç­–ç•¥
      for (let i = 0; i < searchStrategies.length; i++) {
        const searchQuery = searchStrategies[i];
        if (!searchQuery) continue; // è·³é null å€¼
        
        console.log(`ğŸ“ Strategy ${i + 1}: ${searchQuery}`);
        
        const result = await this.tryArxivSearch(searchQuery, cleanTitle);
        if (result) {
          console.log(`âœ… Found via strategy ${i + 1}: ${result}`);
          return result;
        }
      }
      
      console.log(`âŒ No suitable match found for: ${title}`);
      return null;
      
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      console.log(`âš ï¸  arXiv search failed for "${title}":`, errorMessage);
      return null;
    }
  }

  /**
   * å˜—è©¦ä½¿ç”¨ç‰¹å®šæŸ¥è©¢æœå°‹ arXiv
   */
  private async tryArxivSearch(searchQuery: string, cleanTitle: string): Promise<string | null> {
    try {
      const axios = require('axios');
      const apiUrl = `http://export.arxiv.org/api/query?search_query=${encodeURIComponent(searchQuery)}&start=0&max_results=10&sortBy=relevance&sortOrder=descending`;
      
      const response = await axios.get(apiUrl, {
        timeout: 10000,
        headers: {
          'User-Agent': 'PaperMaster/1.0'
        }
      });
      
      if (response.status === 200) {
        const cheerio = require('cheerio');
        const $ = cheerio.load(response.data, { xmlMode: true });
        
        const entries = $('entry');
        console.log(`ğŸ“Š Found ${entries.length} potential matches`);
        
        for (let i = 0; i < entries.length; i++) {
          const entry = entries.eq(i);
          const arxivTitle = entry.find('title').text().trim();
          const arxivId = entry.find('id').text().trim();
          
          // è¨ˆç®—æ¨™é¡Œç›¸ä¼¼åº¦
          const similarity = this.calculateTitleSimilarity(cleanTitle, arxivTitle);
          console.log(`ğŸ“‹ Match ${i + 1}: similarity=${similarity.toFixed(2)}, title="${arxivTitle.substring(0, 50)}..."`);
          
          // å¦‚æœç›¸ä¼¼åº¦è¶³å¤ é«˜ï¼Œè¿”å›é€™å€‹URL
          if (similarity > 0.6) { // é™ä½é–¾å€¼ä»¥æ•ç²æ›´å¤šæ½›åœ¨åŒ¹é…
            const arxivUrl = arxivId.replace('http://arxiv.org/abs/', 'https://arxiv.org/abs/');
            console.log(`âœ… Found matching paper: ${arxivUrl}`);
            return arxivUrl;
          }
        }
      }
      
      return null;
    } catch (error) {
      console.log(`âš ï¸  Search strategy failed:`, error);
      return null;
    }
  }

  /**
   * è¨ˆç®—å…©å€‹æ¨™é¡Œä¹‹é–“çš„ç›¸ä¼¼åº¦
   */
  private calculateTitleSimilarity(title1: string, title2: string): number {
    const normalize = (s: string) => s.toLowerCase()
      .replace(/[^\w\s]/g, ' ')
      .replace(/\s+/g, ' ')
      .trim();
    
    const t1 = normalize(title1);
    const t2 = normalize(title2);
    
    if (t1 === t2) return 1.0;
    
    // ç°¡å–®çš„è©èªé‡ç–Šè¨ˆç®—
    const words1 = new Set(t1.split(' ').filter(w => w.length > 2));
    const words2 = new Set(t2.split(' ').filter(w => w.length > 2));
    
    const intersection = new Set([...words1].filter(x => words2.has(x)));
    const union = new Set([...words1, ...words2]);
    
    return intersection.size / union.size;
  }

  /**
   * ç‚ºå¼•ç”¨ç”Ÿæˆå”¯ä¸€ID
   */
  private generateCitationId(citation: any): string {
    if (citation.id) {
      return `cite_${citation.id}`;
    }
    
    // åŸºæ–¼æ¨™é¡Œç”ŸæˆID
    if (citation.title) {
      return `cite_${citation.title.toLowerCase().replace(/[^a-z0-9]/g, '_').substring(0, 50)}`;
    }
    
    // å‚™ç”¨æ–¹æ¡ˆ
    return `cite_${Math.random().toString(36).substring(2, 15)}`;
  }

  /**
   * æª¢æŸ¥æ‰€éœ€æœå‹™æ˜¯å¦å¯ç”¨ï¼ˆç§æœ‰æ–¹æ³•ï¼‰
   */
  private async checkServicesPrivate(): Promise<{ grobid: boolean; llm: boolean }> {
    const [grobidReady, llmReady] = await Promise.all([
      this.grobidService.testGrobidConnection(),
      this.relationshipAnalyzer.testLLMConnection()
    ]);

    console.log(`Service Status - GROBID: ${grobidReady ? 'âœ…' : 'âŒ'}, LLM: ${llmReady ? 'âœ…' : 'âŒ'}`);

    return {
      grobid: grobidReady,
      llm: llmReady
    };
  }

  /**
   * ç²å–ä¸¦æ·»åŠ  Derivative Works åˆ°åœ–ä¸­
   */
  private async appendDerivativeWorks(graph: PaperGraph, inputPapers: PaperMetadata[]): Promise<PaperGraph> {
    console.log(`ğŸ” Fetching derivative works for ${inputPapers.length} papers...`);
    
    for (const paper of inputPapers) {
      try {
        const arxivId = paper.arxivId;
        let citingPapers: Array<{
          id: string; title: string; authors: string[]; year?: string; abstract?: string; url?: string; citationCount?: number;
        }> = [];

        console.log(`ğŸ” [Derivative] Processing paper: "${paper.title.substring(0, 50)}..." (arXiv ID: ${arxivId || 'none'})`);

        // 1) å„ªå…ˆç”¨ arXiv ID
        if (arxivId) {
          console.log(`   ğŸ“¡ Querying by arXiv ID: ${arxivId}`);
          try {
            citingPapers = await SemanticScholarService.getAllCitingPapers(arxivId, {
              maxResults: 50, // å‡å°‘åˆ°50ï¼Œé¿å…å¤ªå¤šèŠ‚ç‚¹
              pagesToFetch: 2,
              fetchAllAvailable: false
            });
            console.log(`   âœ… Found ${citingPapers.length} citing papers via arXiv ID`);
          } catch (error: any) {
            console.warn(`   âš ï¸  arXiv ID query failed:`, error.message);
          }
        }

        // 2) è‹¥ç„¡ arXiv ID æˆ–æŸ¥ä¸åˆ°ï¼Œæ”¹ç”¨ Title+Authors+Year æ‹¿ paperId å†æŸ¥ citing
        if (citingPapers.length === 0 && paper.title) {
          console.log(`   ğŸ“¡ Fallback: Querying by Title+Authors+Year`);
          try {
            const search = await SemanticScholarService.queryByTitleAndAuthors(paper.title, paper.authors, paper.year);
            if (search.success && search.data?.paperId) {
              console.log(`   âœ… Found paperId: ${search.data.paperId}`);
              citingPapers = await SemanticScholarService.getAllCitingPapers(search.data.paperId, {
                maxResults: 50,
                pagesToFetch: 2,
                fetchAllAvailable: false
              });
              console.log(`   âœ… Found ${citingPapers.length} citing papers via paperId`);
            } else {
              console.warn(`   âš ï¸  Title search failed:`, search.error);
            }
          } catch (error: any) {
            console.warn(`   âš ï¸  Title search error:`, error.message);
          }
        }

        if (citingPapers.length === 0) {
          console.warn(`   âŒ No derivative works found for "${paper.title.substring(0, 50)}..."`);
          continue;
        }

        console.log(`ğŸ“„ Found ${citingPapers.length} derivative works for "${paper.title.substring(0, 50)}..."`);

        // è·å–è¾“å…¥è®ºæ–‡çš„èŠ‚ç‚¹ IDï¼ˆéœ€è¦åŒ¹é…ï¼‰
        const inputPaperNode = graph.nodes.find(n => {
          // å°è¯•åŒ¹é…ï¼šé€šè¿‡ IDã€URL æˆ–æ ‡é¢˜
          return n.id === paper.id || 
                 (paper.url && n.url === paper.url) ||
                 (n.title && paper.title && n.title.toLowerCase().trim() === paper.title.toLowerCase().trim());
        });

        if (!inputPaperNode) {
          console.warn(`   âš ï¸  Could not find input paper node in graph for: ${paper.title.substring(0, 50)}... (ID: ${paper.id})`);
          continue;
        }

        const inputNodeId = inputPaperNode.id;
        console.log(`   âœ… Matched input paper node ID: ${inputNodeId}`);

        for (const citingPaper of citingPapers) {
          // ç”Ÿæˆç¨³å®šçš„èŠ‚ç‚¹ ID
          const derivativeNodeId = citingPaper.id || `derivative_${citingPaper.title.toLowerCase().replace(/[^a-z0-9]/g, '_').substring(0, 50)}`;
          
          // 1. æ·»åŠ ç¯€é» (å¦‚æœä¸å­˜åœ¨)
          const existingNodeIndex = graph.nodes.findIndex(n => 
            n.id === derivativeNodeId || 
            (n.title && citingPaper.title && n.title.toLowerCase().trim() === citingPaper.title.toLowerCase().trim())
          );
          
          if (existingNodeIndex === -1) {
            graph.nodes.push({
              id: derivativeNodeId,
              title: citingPaper.title,
              authors: citingPaper.authors,
              year: citingPaper.year || 'Unknown',
              abstract: citingPaper.abstract,
              url: citingPaper.url,
              venue: 'Unknown',
              citationCount: citingPaper.citationCount ?? undefined,
              paperCitationCount: citingPaper.citationCount ?? undefined,
            });
          } else {
            // æ›´æ–°ç°æœ‰èŠ‚ç‚¹çš„ citationCountï¼ˆå¦‚æœä¹‹å‰æ²¡æœ‰ï¼‰
            const existingNode = graph.nodes[existingNodeIndex];
            if (!existingNode.citationCount && citingPaper.citationCount) {
              existingNode.citationCount = citingPaper.citationCount;
              existingNode.paperCitationCount = citingPaper.citationCount;
            }
          }

          // 2. æ·»åŠ é‚Š (Derivative -> Input Paper) - ä½¿ç”¨å®é™…çš„èŠ‚ç‚¹ ID
          const finalDerivativeNodeId = existingNodeIndex >= 0 ? graph.nodes[existingNodeIndex].id : derivativeNodeId;
          const edgeExists = graph.edges.some(e => 
            (e.source === finalDerivativeNodeId && e.target === inputNodeId) ||
            ((e as any).from === finalDerivativeNodeId && (e as any).to === inputNodeId)
          );
          
          if (!edgeExists) {
            // åŸºäº citationCount è®¡ç®— strengthï¼ˆ0.3-1.0ï¼‰
            let strength = 0.5; // é»˜è®¤
            if (citingPaper.citationCount && citingPaper.citationCount > 0) {
              // ä½¿ç”¨å¯¹æ•°ç¼©æ”¾ï¼šlog(1 + citationCount) / log(1 + maxCitation)
              strength = Math.min(1.0, 0.3 + (Math.log(1 + citingPaper.citationCount) / Math.log(1 + 100000)) * 0.7);
            }
            
            graph.edges.push({
              source: finalDerivativeNodeId,
              target: inputNodeId,
              relationship: 'builds_on',
              strength: strength,
              description: 'Cites source paper',
              evidence: `Citation from Semantic Scholar (${citingPaper.citationCount || 'unknown'} citations)`
            });
          }
        }
      } catch (error) {
        console.error(`âŒ Failed to fetch derivative works for ${paper.title}:`, error);
      }
    }
    
    return graph;
  }

  /**
   * ç”Ÿæˆè«–æ–‡ ID
   */
  private generatePaperId(url: string): string {
    // å¾ arXiv URL æå– ID
    const arxivMatch = url.match(/arxiv\.org\/abs\/(.+)/);
    if (arxivMatch) {
      return `arxiv_${arxivMatch[1].replace(/[^\w.-]/g, '_')}`;
    }
    
    // å…¶ä»– URL çš„ç°¡å–® hash
    return `paper_${url.split('/').pop()?.replace(/[^\w.-]/g, '_') || 'unknown'}`;
  }

  /**
   * å¾ URL æå–å¹´ä»½ï¼ˆæ”¹é€²çš„å¯¦ç¾ï¼‰
   */
  private extractYearFromUrl(url: string): string | null {
    // arXiv URL æ ¼å¼: https://arxiv.org/abs/YYMM.NNNNN
    const arxivMatch = url.match(/arxiv\.org\/abs\/(\d{2})(\d{2})\./);
    if (arxivMatch) {
      const year = parseInt(arxivMatch[1]);
      // arXiv ä½¿ç”¨2ä½å¹´ä»½ï¼Œ92-99è¡¨ç¤º1992-1999ï¼Œ00-91è¡¨ç¤º2000-2091
      if (year >= 92) {
        return `19${year}`;
      } else {
        return `20${year}`;
      }
    }
    
    // å…¶ä»–æ ¼å¼çš„å¹´ä»½æå–
    const yearMatch = url.match(/(\d{4})/);
    if (yearMatch) {
      const year = parseInt(yearMatch[1]);
      if (year >= 1990 && year <= 2030) {
        return yearMatch[1];
      }
    }
    
    return null;
  }

  /**
   * å‰µå»ºåŸºæœ¬çš„å¼•ç”¨è«–æ–‡å°è±¡ï¼ˆç•¶ç„¡æ³•é€šéGROBIDæå–æ™‚ä½¿ç”¨ï¼‰
   */
  private createBasicCitedPaper(citation: any): PaperMetadata {
    const citationId = this.generateCitationId(citation);
    
    return {
      id: citationId,
      title: citation.title || 'Unknown Title',
      authors: citation.authors || [],
      year: citation.year || 'Unknown',
      abstract: undefined,
      venue: undefined,
      citations: [] // åŸºæœ¬å¼•ç”¨è«–æ–‡æ²’æœ‰é€²ä¸€æ­¥çš„å¼•ç”¨ä¿¡æ¯
    };
  }

  /**
   * æ¸¬è©¦æ•´å€‹æµç¨‹
   */
  async testWorkflow(sampleUrls: string[] = [
    'https://arxiv.org/abs/1706.03762', // Transformer
    'https://arxiv.org/abs/2010.11929'  // Vision Transformer
  ]): Promise<GraphBuildResult> {
    console.log('\n=== Testing Complete Workflow ===');
    console.log('Sample papers:', sampleUrls);
    
    return await this.buildGraphFromUrls(sampleUrls);
  }
}
